[epoch: 1, batch:     21] loss: 0.08991 time model: 1.30457 acc: 1.75000
[epoch: 1, batch:     41] loss: 0.08336 time model: 2.60634 acc: 4.15000
[epoch: 1, batch:     61] loss: 0.08045 time model: 3.90670 acc: 6.90000
[epoch: 1, batch:     81] loss: 0.07918 time model: 5.20701 acc: 9.80000
[epoch: 1, batch:    101] loss: 0.07846 time model: 6.50867 acc: 12.45000
[epoch: 1, batch:    121] loss: 0.07767 time model: 7.80946 acc: 15.40000
[epoch: 1, batch:    141] loss: 0.07711 time model: 9.10977 acc: 18.95000
[epoch: 1, batch:    161] loss: 0.07669 time model: 10.41170 acc: 22.30000
[epoch: 1, batch:    181] loss: 0.07628 time model: 11.71181 acc: 26.45000
[epoch: 1, batch:    201] loss: 0.07584 time model: 13.01216 acc: 30.75000
[epoch: 1, batch:    221] loss: 0.07571 time model: 14.31350 acc: 34.35000
[epoch: 1, batch:    241] loss: 0.07545 time model: 15.61428 acc: 37.55000
[epoch: 1, batch:    261] loss: 0.07524 time model: 16.91447 acc: 40.75000
[epoch: 1, batch:    281] loss: 0.07507 time model: 18.21577 acc: 44.10000
[epoch: 1, batch:    301] loss: 0.07490 time model: 19.51645 acc: 48.20000
[epoch: 1, batch:    321] loss: 0.07475 time model: 20.81671 acc: 51.95000
[epoch: 1, batch:    341] loss: 0.07459 time model: 22.11825 acc: 55.90000
[epoch: 1, batch:    361] loss: 0.07447 time model: 23.41920 acc: 60.35000
[epoch: 1, batch:    381] loss: 0.07438 time model: 24.71853 acc: 64.55000
[epoch: 1, batch:    401] loss: 0.07429 time model: 26.01949 acc: 68.40000
[epoch: 1, batch:    421] loss: 0.07420 time model: 27.31914 acc: 72.95000
[epoch: 1, batch:    441] loss: 0.07405 time model: 28.62058 acc: 77.45000
[epoch: 1, batch:    461] loss: 0.07401 time model: 29.92112 acc: 81.25000
[epoch: 1, batch:    481] loss: 0.07394 time model: 31.22141 acc: 85.00000
[epoch: 1, batch:    501] loss: 0.07389 time model: 32.52186 acc: 90.55000
[epoch: 1, batch:    521] loss: 0.07377 time model: 33.82335 acc: 94.60000
[epoch: 1, batch:    541] loss: 0.07370 time model: 35.12466 acc: 98.15000
[epoch: 1, batch:    561] loss: 0.07379 time model: 36.42526 acc: 101.50000
[epoch: 1, batch:    581] loss: 0.07372 time model: 37.72625 acc: 105.45000
[epoch: 1, batch:    601] loss: 0.07364 time model: 39.02691 acc: 110.30000
[epoch: 1, batch:    621] loss: 0.07358 time model: 40.32733 acc: 115.20000
[epoch: 1, batch:    641] loss: 0.07353 time model: 41.62925 acc: 119.35000
[epoch: 1, batch:    661] loss: 0.07358 time model: 42.91386 acc: 122.20000
[epoch: 1, batch:     21] loss: 0.07388 time model: 0.84493 acc: 3.45000
[epoch: 1, batch:     41] loss: 0.07440 time model: 1.69005 acc: 6.70000
[epoch: 1, batch:     61] loss: 0.07498 time model: 2.53616 acc: 10.15000
[epoch: 1, batch:     81] loss: 0.07513 time model: 3.38132 acc: 13.50000
epoch:1 train loss: 0.07358461962692886 train acc: 0.11580194266761432 valid loss: 0.07556989871118713 valid acc: 0.10554908808692277
[epoch: 2, batch:     21] loss: 0.06991 time model: 1.30503 acc: 4.25000
[epoch: 2, batch:     41] loss: 0.06979 time model: 2.61022 acc: 9.30000
[epoch: 2, batch:     61] loss: 0.07183 time model: 3.91350 acc: 13.60000
[epoch: 2, batch:     81] loss: 0.07211 time model: 5.21721 acc: 17.15000
[epoch: 2, batch:    101] loss: 0.07195 time model: 6.52130 acc: 20.85000
[epoch: 2, batch:    121] loss: 0.07210 time model: 7.82601 acc: 25.10000
[epoch: 2, batch:    141] loss: 0.07189 time model: 9.12974 acc: 29.70000
[epoch: 2, batch:    161] loss: 0.07183 time model: 10.43475 acc: 34.70000
[epoch: 2, batch:    181] loss: 0.07180 time model: 11.73929 acc: 38.45000
[epoch: 2, batch:    201] loss: 0.07169 time model: 13.04298 acc: 42.90000
[epoch: 2, batch:    221] loss: 0.07181 time model: 14.34698 acc: 47.35000
[epoch: 2, batch:    241] loss: 0.07194 time model: 15.65224 acc: 52.85000
[epoch: 2, batch:    261] loss: 0.07194 time model: 16.95487 acc: 57.95000
[epoch: 2, batch:    281] loss: 0.07190 time model: 18.25892 acc: 63.90000
[epoch: 2, batch:    301] loss: 0.07167 time model: 19.56309 acc: 69.65000
[epoch: 2, batch:    321] loss: 0.07117 time model: 20.86796 acc: 78.50000
[epoch: 2, batch:    341] loss: 0.07037 time model: 22.17293 acc: 89.85000
[epoch: 2, batch:    361] loss: 0.06930 time model: 23.47684 acc: 102.20000
[epoch: 2, batch:    381] loss: 0.06823 time model: 24.78176 acc: 115.45000
[epoch: 2, batch:    401] loss: 0.06722 time model: 26.08532 acc: 129.40000
[epoch: 2, batch:    421] loss: 0.06626 time model: 27.39018 acc: 143.45000
[epoch: 2, batch:    441] loss: 0.06497 time model: 28.69422 acc: 161.50000
[epoch: 2, batch:    461] loss: 0.06375 time model: 29.99976 acc: 179.40000
[epoch: 2, batch:    481] loss: 0.06271 time model: 31.30440 acc: 196.65000
[epoch: 2, batch:    501] loss: 0.06155 time model: 32.60943 acc: 216.25000
[epoch: 2, batch:    521] loss: 0.06035 time model: 33.91423 acc: 236.85000
[epoch: 2, batch:    541] loss: 0.05922 time model: 35.21974 acc: 257.75000
[epoch: 2, batch:    561] loss: 0.05815 time model: 36.52318 acc: 279.50000
[epoch: 2, batch:    581] loss: 0.05697 time model: 37.82762 acc: 302.75000
[epoch: 2, batch:    601] loss: 0.05563 time model: 39.13133 acc: 329.40000
[epoch: 2, batch:    621] loss: 0.05439 time model: 40.43539 acc: 356.00000
[epoch: 2, batch:    641] loss: 0.05324 time model: 41.74047 acc: 382.50000
[epoch: 2, batch:    661] loss: 0.05212 time model: 43.02642 acc: 409.00000
[epoch: 2, batch:     21] loss: 0.01791 time model: 0.84495 acc: 25.50000
[epoch: 2, batch:     41] loss: 0.01817 time model: 1.68999 acc: 51.05000
[epoch: 2, batch:     61] loss: 0.01816 time model: 2.53562 acc: 77.20000
[epoch: 2, batch:     81] loss: 0.01830 time model: 3.37998 acc: 102.95000
epoch:2 train loss: 0.05212200360186883 train acc: 0.38758588012319356 valid loss: 0.018389310394325228 valid acc: 0.8044237485448196
[epoch: 3, batch:     21] loss: 0.01906 time model: 1.30696 acc: 26.05000
[epoch: 3, batch:     41] loss: 0.01801 time model: 2.61197 acc: 52.00000
[epoch: 3, batch:     61] loss: 0.02066 time model: 3.91745 acc: 75.00000
[epoch: 3, batch:     81] loss: 0.02114 time model: 5.22348 acc: 98.90000
[epoch: 3, batch:    101] loss: 0.02029 time model: 6.52754 acc: 124.40000
[epoch: 3, batch:    121] loss: 0.01918 time model: 7.83439 acc: 151.75000
[epoch: 3, batch:    141] loss: 0.01829 time model: 9.14045 acc: 179.25000
[epoch: 3, batch:    161] loss: 0.01726 time model: 10.44391 acc: 208.25000
[epoch: 3, batch:    181] loss: 0.01652 time model: 11.74578 acc: 237.25000
[epoch: 3, batch:    201] loss: 0.01662 time model: 13.04780 acc: 263.35000
[epoch: 3, batch:    221] loss: 0.01673 time model: 14.34929 acc: 288.90000
[epoch: 3, batch:    241] loss: 0.01653 time model: 15.65034 acc: 316.35000
[epoch: 3, batch:    261] loss: 0.01617 time model: 16.95182 acc: 344.55000
[epoch: 3, batch:    281] loss: 0.01583 time model: 18.25414 acc: 372.85000
[epoch: 3, batch:    301] loss: 0.01547 time model: 19.55696 acc: 401.30000
[epoch: 3, batch:    321] loss: 0.01508 time model: 20.85986 acc: 430.40000
[epoch: 3, batch:    341] loss: 0.01469 time model: 22.16266 acc: 459.90000
[epoch: 3, batch:    361] loss: 0.01418 time model: 23.46577 acc: 490.25000
[epoch: 3, batch:    381] loss: 0.01386 time model: 24.76917 acc: 519.50000
[epoch: 3, batch:    401] loss: 0.01369 time model: 26.07151 acc: 548.20000
[epoch: 3, batch:    421] loss: 0.01345 time model: 27.37437 acc: 577.50000
[epoch: 3, batch:    441] loss: 0.01311 time model: 28.67711 acc: 607.80000
[epoch: 3, batch:    461] loss: 0.01290 time model: 29.98023 acc: 637.00000
[epoch: 3, batch:    481] loss: 0.01276 time model: 31.28316 acc: 665.65000
[epoch: 3, batch:    501] loss: 0.01264 time model: 32.58645 acc: 694.45000
[epoch: 3, batch:    521] loss: 0.01246 time model: 33.88861 acc: 723.95000
[epoch: 3, batch:    541] loss: 0.01235 time model: 35.18973 acc: 752.95000
[epoch: 3, batch:    561] loss: 0.01226 time model: 36.49192 acc: 781.55000
[epoch: 3, batch:    581] loss: 0.01208 time model: 37.79381 acc: 811.15000
[epoch: 3, batch:    601] loss: 0.01190 time model: 39.09580 acc: 841.10000
[epoch: 3, batch:    621] loss: 0.01168 time model: 40.39849 acc: 871.60000
[epoch: 3, batch:    641] loss: 0.01148 time model: 41.70064 acc: 902.05000
[epoch: 3, batch:    661] loss: 0.01132 time model: 42.98196 acc: 931.60000
[epoch: 3, batch:     21] loss: 0.01293 time model: 0.84205 acc: 27.55000
[epoch: 3, batch:     41] loss: 0.01296 time model: 1.68289 acc: 54.85000
[epoch: 3, batch:     61] loss: 0.01293 time model: 2.52430 acc: 82.30000
[epoch: 3, batch:     81] loss: 0.01391 time model: 3.36418 acc: 109.15000
epoch:3 train loss: 0.011319642862602028 train acc: 0.8828239753612888 valid loss: 0.013873099997425708 valid acc: 0.8537058595265813
[epoch: 4, batch:     21] loss: 0.00594 time model: 1.30367 acc: 30.15000
[epoch: 4, batch:     41] loss: 0.00499 time model: 2.60708 acc: 60.85000
[epoch: 4, batch:     61] loss: 0.00553 time model: 3.90954 acc: 90.75000
[epoch: 4, batch:     81] loss: 0.00502 time model: 5.21229 acc: 121.90000
[epoch: 4, batch:    101] loss: 0.00512 time model: 6.51499 acc: 152.25000
[epoch: 4, batch:    121] loss: 0.00520 time model: 7.81811 acc: 182.50000
[epoch: 4, batch:    141] loss: 0.00504 time model: 9.12119 acc: 213.60000
[epoch: 4, batch:    161] loss: 0.00545 time model: 10.42393 acc: 243.00000
[epoch: 4, batch:    181] loss: 0.00544 time model: 11.72581 acc: 273.25000
[epoch: 4, batch:    201] loss: 0.00546 time model: 13.02722 acc: 303.45000
[epoch: 4, batch:    221] loss: 0.00534 time model: 14.32855 acc: 334.20000
[epoch: 4, batch:    241] loss: 0.00537 time model: 15.63482 acc: 364.50000
[epoch: 4, batch:    261] loss: 0.00542 time model: 16.94131 acc: 394.40000
[epoch: 4, batch:    281] loss: 0.00541 time model: 18.24714 acc: 424.95000
[epoch: 4, batch:    301] loss: 0.00548 time model: 19.55300 acc: 454.95000
[epoch: 4, batch:    321] loss: 0.00544 time model: 20.85880 acc: 485.55000
[epoch: 4, batch:    341] loss: 0.00540 time model: 22.16402 acc: 516.00000
[epoch: 4, batch:    361] loss: 0.00543 time model: 23.46996 acc: 546.00000
[epoch: 4, batch:    381] loss: 0.00537 time model: 24.77552 acc: 576.75000
[epoch: 4, batch:    401] loss: 0.00539 time model: 26.08119 acc: 607.10000
[epoch: 4, batch:    421] loss: 0.00534 time model: 27.38596 acc: 637.45000
[epoch: 4, batch:    441] loss: 0.00525 time model: 28.69235 acc: 668.30000
[epoch: 4, batch:    461] loss: 0.00522 time model: 29.99807 acc: 698.60000
[epoch: 4, batch:    481] loss: 0.00526 time model: 31.30280 acc: 728.85000
[epoch: 4, batch:    501] loss: 0.00522 time model: 32.60895 acc: 759.55000
[epoch: 4, batch:    521] loss: 0.00519 time model: 33.91480 acc: 790.40000
[epoch: 4, batch:    541] loss: 0.00511 time model: 35.22067 acc: 821.65000
[epoch: 4, batch:    561] loss: 0.00516 time model: 36.52664 acc: 851.65000
[epoch: 4, batch:    581] loss: 0.00519 time model: 37.83268 acc: 881.40000
[epoch: 4, batch:    601] loss: 0.00520 time model: 39.13743 acc: 911.50000
[epoch: 4, batch:    621] loss: 0.00517 time model: 40.44371 acc: 941.90000
[epoch: 4, batch:    641] loss: 0.00518 time model: 41.74883 acc: 972.25000
[epoch: 4, batch:    661] loss: 0.00519 time model: 43.03409 acc: 1001.85000
[epoch: 4, batch:     21] loss: 0.03290 time model: 0.84556 acc: 21.80000
[epoch: 4, batch:     41] loss: 0.03474 time model: 1.69211 acc: 43.80000
[epoch: 4, batch:     61] loss: 0.03475 time model: 2.53765 acc: 66.25000
[epoch: 4, batch:     81] loss: 0.03447 time model: 3.38250 acc: 88.95000
epoch:4 train loss: 0.005194581067200606 train acc: 0.9493958777540867 valid loss: 0.03468427178260195 valid acc: 0.6942180830422973
[epoch: 5, batch:     21] loss: 0.00515 time model: 1.30564 acc: 30.30000
[epoch: 5, batch:     41] loss: 0.00480 time model: 2.61171 acc: 60.70000
[epoch: 5, batch:     61] loss: 0.00614 time model: 3.91707 acc: 90.15000
[epoch: 5, batch:     81] loss: 0.00615 time model: 5.22296 acc: 120.40000
[epoch: 5, batch:    101] loss: 0.00574 time model: 6.52723 acc: 151.10000
[epoch: 5, batch:    121] loss: 0.00533 time model: 7.83300 acc: 182.15000
[epoch: 5, batch:    141] loss: 0.00488 time model: 9.13775 acc: 213.40000
[epoch: 5, batch:    161] loss: 0.00473 time model: 10.44347 acc: 244.55000
[epoch: 5, batch:    181] loss: 0.00464 time model: 11.74841 acc: 275.25000
[epoch: 5, batch:    201] loss: 0.00458 time model: 13.05385 acc: 305.85000
[epoch: 5, batch:    221] loss: 0.00478 time model: 14.35866 acc: 335.85000
[epoch: 5, batch:    241] loss: 0.00474 time model: 15.66376 acc: 366.70000
[epoch: 5, batch:    261] loss: 0.00468 time model: 16.96900 acc: 397.40000
[epoch: 5, batch:    281] loss: 0.00463 time model: 18.27415 acc: 428.30000
[epoch: 5, batch:    301] loss: 0.00457 time model: 19.57972 acc: 459.15000
[epoch: 5, batch:    321] loss: 0.00445 time model: 20.88563 acc: 490.35000
[epoch: 5, batch:    341] loss: 0.00437 time model: 22.19029 acc: 521.60000
[epoch: 5, batch:    361] loss: 0.00425 time model: 23.49674 acc: 553.00000
[epoch: 5, batch:    381] loss: 0.00431 time model: 24.80176 acc: 583.55000
[epoch: 5, batch:    401] loss: 0.00428 time model: 26.10788 acc: 614.35000
[epoch: 5, batch:    421] loss: 0.00443 time model: 27.41304 acc: 644.05000
[epoch: 5, batch:    441] loss: 0.00438 time model: 28.71889 acc: 675.10000
[epoch: 5, batch:    461] loss: 0.00437 time model: 30.02179 acc: 705.80000
[epoch: 5, batch:    481] loss: 0.00433 time model: 31.32476 acc: 736.85000
[epoch: 5, batch:    501] loss: 0.00428 time model: 32.62812 acc: 767.75000
[epoch: 5, batch:    521] loss: 0.00421 time model: 33.93087 acc: 799.00000
[epoch: 5, batch:    541] loss: 0.00416 time model: 35.23347 acc: 830.00000
[epoch: 5, batch:    561] loss: 0.00426 time model: 36.53535 acc: 859.85000
[epoch: 5, batch:    581] loss: 0.00436 time model: 37.83780 acc: 889.45000
[epoch: 5, batch:    601] loss: 0.00452 time model: 39.14048 acc: 918.30000
[epoch: 5, batch:    621] loss: 0.00456 time model: 40.44346 acc: 948.30000
[epoch: 5, batch:    641] loss: 0.00457 time model: 41.74601 acc: 978.80000
[epoch: 5, batch:    661] loss: 0.00453 time model: 43.02962 acc: 1009.30000
[epoch: 5, batch:     21] loss: 0.01053 time model: 0.84071 acc: 28.35000
[epoch: 5, batch:     41] loss: 0.01081 time model: 1.68231 acc: 57.15000
[epoch: 5, batch:     61] loss: 0.01099 time model: 2.52356 acc: 85.55000
[epoch: 5, batch:     81] loss: 0.01087 time model: 3.36414 acc: 114.20000
epoch:5 train loss: 0.004527775567484761 train acc: 0.9564558161573087 valid loss: 0.010893447036238017 valid acc: 0.8917345750873108
[epoch: 6, batch:     21] loss: 0.00436 time model: 1.30157 acc: 30.30000
[epoch: 6, batch:     41] loss: 0.00344 time model: 2.60454 acc: 61.45000
[epoch: 6, batch:     61] loss: 0.00308 time model: 3.90697 acc: 92.75000
[epoch: 6, batch:     81] loss: 0.00292 time model: 5.21029 acc: 123.90000
[epoch: 6, batch:    101] loss: 0.00299 time model: 6.51306 acc: 154.80000
[epoch: 6, batch:    121] loss: 0.00295 time model: 7.81569 acc: 185.95000
[epoch: 6, batch:    141] loss: 0.00286 time model: 9.11856 acc: 217.35000
[epoch: 6, batch:    161] loss: 0.00297 time model: 10.42111 acc: 248.20000
[epoch: 6, batch:    181] loss: 0.00297 time model: 11.72395 acc: 279.20000
[epoch: 6, batch:    201] loss: 0.00318 time model: 13.02531 acc: 309.55000
[epoch: 6, batch:    221] loss: 0.00319 time model: 14.32746 acc: 340.20000
[epoch: 6, batch:    241] loss: 0.00317 time model: 15.63008 acc: 371.45000
[epoch: 6, batch:    261] loss: 0.00308 time model: 16.93335 acc: 402.80000
[epoch: 6, batch:    281] loss: 0.00299 time model: 18.23479 acc: 434.30000
[epoch: 6, batch:    301] loss: 0.00296 time model: 19.53681 acc: 465.70000
[epoch: 6, batch:    321] loss: 0.00292 time model: 20.84003 acc: 497.05000
[epoch: 6, batch:    341] loss: 0.00299 time model: 22.14243 acc: 527.70000
[epoch: 6, batch:    361] loss: 0.00302 time model: 23.44534 acc: 558.65000
[epoch: 6, batch:    381] loss: 0.00306 time model: 24.74833 acc: 589.45000
[epoch: 6, batch:    401] loss: 0.00305 time model: 26.05062 acc: 620.40000
[epoch: 6, batch:    421] loss: 0.00309 time model: 27.35352 acc: 651.00000
[epoch: 6, batch:    441] loss: 0.00304 time model: 28.65512 acc: 682.55000
[epoch: 6, batch:    461] loss: 0.00306 time model: 29.95743 acc: 713.40000
[epoch: 6, batch:    481] loss: 0.00306 time model: 31.25964 acc: 744.45000
[epoch: 6, batch:    501] loss: 0.00307 time model: 32.56163 acc: 775.25000
[epoch: 6, batch:    521] loss: 0.00305 time model: 33.86679 acc: 806.55000
[epoch: 6, batch:    541] loss: 0.00305 time model: 35.17308 acc: 837.70000
[epoch: 6, batch:    561] loss: 0.00301 time model: 36.47930 acc: 869.10000
[epoch: 6, batch:    581] loss: 0.00298 time model: 37.78529 acc: 900.55000
[epoch: 6, batch:    601] loss: 0.00298 time model: 39.09055 acc: 931.45000
[epoch: 6, batch:    621] loss: 0.00296 time model: 40.39673 acc: 962.65000
[epoch: 6, batch:    641] loss: 0.00298 time model: 41.70297 acc: 993.65000
[epoch: 6, batch:    661] loss: 0.00302 time model: 42.98855 acc: 1023.45000
[epoch: 6, batch:     21] loss: 0.00788 time model: 0.84608 acc: 29.35000
[epoch: 6, batch:     41] loss: 0.00877 time model: 1.69333 acc: 58.55000
[epoch: 6, batch:     61] loss: 0.00820 time model: 2.54004 acc: 88.25000
[epoch: 6, batch:     81] loss: 0.00888 time model: 3.38588 acc: 117.45000
epoch:6 train loss: 0.003016890141317783 train acc: 0.9698649609097371 valid loss: 0.009014567731076263 valid acc: 0.9177337989910749
[epoch: 7, batch:     21] loss: 0.00481 time model: 1.30726 acc: 30.65000
[epoch: 7, batch:     41] loss: 0.00378 time model: 2.61292 acc: 61.85000
[epoch: 7, batch:     61] loss: 0.00330 time model: 3.91955 acc: 93.00000
[epoch: 7, batch:     81] loss: 0.00290 time model: 5.22627 acc: 124.50000
[epoch: 7, batch:    101] loss: 0.00273 time model: 6.53293 acc: 155.90000
[epoch: 7, batch:    121] loss: 0.00262 time model: 7.83836 acc: 187.40000
[epoch: 7, batch:    141] loss: 0.00253 time model: 9.14406 acc: 218.90000
[epoch: 7, batch:    161] loss: 0.00255 time model: 10.45018 acc: 250.00000
[epoch: 7, batch:    181] loss: 0.00249 time model: 11.75577 acc: 281.40000
[epoch: 7, batch:    201] loss: 0.00259 time model: 13.06240 acc: 312.40000
[epoch: 7, batch:    221] loss: 0.00272 time model: 14.36878 acc: 343.20000
[epoch: 7, batch:    241] loss: 0.00269 time model: 15.67457 acc: 374.40000
[epoch: 7, batch:    261] loss: 0.00261 time model: 16.98051 acc: 405.95000
[epoch: 7, batch:    281] loss: 0.00259 time model: 18.28618 acc: 437.10000
[epoch: 7, batch:    301] loss: 0.00258 time model: 19.59247 acc: 468.15000
[epoch: 7, batch:    321] loss: 0.00253 time model: 20.89877 acc: 499.60000
[epoch: 7, batch:    341] loss: 0.00248 time model: 22.20425 acc: 531.10000
[epoch: 7, batch:    361] loss: 0.00248 time model: 23.50865 acc: 562.10000
[epoch: 7, batch:    381] loss: 0.00248 time model: 24.81362 acc: 593.40000
[epoch: 7, batch:    401] loss: 0.00253 time model: 26.11921 acc: 624.30000
[epoch: 7, batch:    421] loss: 0.00254 time model: 27.42478 acc: 655.10000
[epoch: 7, batch:    441] loss: 0.00254 time model: 28.72973 acc: 686.40000
[epoch: 7, batch:    461] loss: 0.00254 time model: 30.03529 acc: 717.55000
[epoch: 7, batch:    481] loss: 0.00250 time model: 31.34079 acc: 749.00000
[epoch: 7, batch:    501] loss: 0.00248 time model: 32.64639 acc: 780.45000
[epoch: 7, batch:    521] loss: 0.00247 time model: 33.95143 acc: 811.70000
[epoch: 7, batch:    541] loss: 0.00248 time model: 35.25704 acc: 842.85000
[epoch: 7, batch:    561] loss: 0.00247 time model: 36.56356 acc: 874.05000
[epoch: 7, batch:    581] loss: 0.00246 time model: 37.86977 acc: 905.25000
[epoch: 7, batch:    601] loss: 0.00247 time model: 39.17578 acc: 936.40000
[epoch: 7, batch:    621] loss: 0.00248 time model: 40.48099 acc: 967.65000
[epoch: 7, batch:    641] loss: 0.00248 time model: 41.78656 acc: 998.80000
[epoch: 7, batch:    661] loss: 0.00251 time model: 43.07392 acc: 1029.05000
[epoch: 7, batch:     21] loss: 0.01818 time model: 0.84635 acc: 27.40000
[epoch: 7, batch:     41] loss: 0.01791 time model: 1.69395 acc: 54.10000
[epoch: 7, batch:     61] loss: 0.01704 time model: 2.54104 acc: 81.65000
[epoch: 7, batch:     81] loss: 0.01653 time model: 3.38697 acc: 109.45000
epoch:7 train loss: 0.0025051364678694466 train acc: 0.9751717602463871 valid loss: 0.016668172147693124 valid acc: 0.8548700038804812
[epoch: 8, batch:     21] loss: 0.00656 time model: 1.30546 acc: 29.85000
[epoch: 8, batch:     41] loss: 0.00454 time model: 2.60786 acc: 61.05000
[epoch: 8, batch:     61] loss: 0.00398 time model: 3.90952 acc: 91.90000
[epoch: 8, batch:     81] loss: 0.00359 time model: 5.21299 acc: 123.20000
[epoch: 8, batch:    101] loss: 0.00335 time model: 6.51476 acc: 154.45000
[epoch: 8, batch:    121] loss: 0.00306 time model: 7.81592 acc: 186.05000
[epoch: 8, batch:    141] loss: 0.00291 time model: 9.11789 acc: 217.45000
[epoch: 8, batch:    161] loss: 0.00290 time model: 10.41940 acc: 248.55000
[epoch: 8, batch:    181] loss: 0.00283 time model: 11.72167 acc: 279.65000
[epoch: 8, batch:    201] loss: 0.00276 time model: 13.02428 acc: 311.00000
[epoch: 8, batch:    221] loss: 0.00267 time model: 14.32692 acc: 342.60000
[epoch: 8, batch:    241] loss: 0.00261 time model: 15.62886 acc: 374.05000
[epoch: 8, batch:    261] loss: 0.00264 time model: 16.93015 acc: 405.15000
[epoch: 8, batch:    281] loss: 0.00272 time model: 18.23268 acc: 436.30000
[epoch: 8, batch:    301] loss: 0.00271 time model: 19.53487 acc: 467.35000
[epoch: 8, batch:    321] loss: 0.00279 time model: 20.83651 acc: 497.95000
[epoch: 8, batch:    341] loss: 0.00294 time model: 22.13912 acc: 527.90000
[epoch: 8, batch:    361] loss: 0.00406 time model: 23.43987 acc: 555.25000
[epoch: 8, batch:    381] loss: 0.00453 time model: 24.74107 acc: 583.20000
[epoch: 8, batch:    401] loss: 0.00444 time model: 26.04279 acc: 614.30000
[epoch: 8, batch:    421] loss: 0.00434 time model: 27.34480 acc: 645.75000
[epoch: 8, batch:    441] loss: 0.00425 time model: 28.64621 acc: 677.00000
[epoch: 8, batch:    461] loss: 0.00413 time model: 29.94846 acc: 708.65000
[epoch: 8, batch:    481] loss: 0.00407 time model: 31.25070 acc: 739.90000
[epoch: 8, batch:    501] loss: 0.00398 time model: 32.55244 acc: 771.45000
[epoch: 8, batch:    521] loss: 0.00389 time model: 33.85513 acc: 803.00000
[epoch: 8, batch:    541] loss: 0.00380 time model: 35.15853 acc: 834.55000
[epoch: 8, batch:    561] loss: 0.00378 time model: 36.46004 acc: 865.50000
[epoch: 8, batch:    581] loss: 0.00369 time model: 37.76094 acc: 897.10000
[epoch: 8, batch:    601] loss: 0.00365 time model: 39.06314 acc: 928.30000
[epoch: 8, batch:    621] loss: 0.00361 time model: 40.36555 acc: 959.40000
[epoch: 8, batch:    641] loss: 0.00358 time model: 41.66845 acc: 990.65000
[epoch: 8, batch:    661] loss: 0.00354 time model: 42.95015 acc: 1021.15000
[epoch: 8, batch:     21] loss: 0.01929 time model: 0.84233 acc: 27.10000
[epoch: 8, batch:     41] loss: 0.01949 time model: 1.68509 acc: 54.00000
[epoch: 8, batch:     61] loss: 0.01882 time model: 2.52629 acc: 81.20000
[epoch: 8, batch:     81] loss: 0.01835 time model: 3.36709 acc: 108.25000
epoch:8 train loss: 0.0035449267284063416 train acc: 0.9676853826107558 valid loss: 0.018484067630064688 valid acc: 0.8451688009313155
[epoch: 9, batch:     21] loss: 0.00159 time model: 1.30258 acc: 31.55000
[epoch: 9, batch:     41] loss: 0.00184 time model: 2.60414 acc: 62.80000
[epoch: 9, batch:     61] loss: 0.00212 time model: 3.90604 acc: 93.80000
[epoch: 9, batch:     81] loss: 0.00287 time model: 5.20766 acc: 124.45000
[epoch: 9, batch:    101] loss: 0.00404 time model: 6.50914 acc: 154.40000
[epoch: 9, batch:    121] loss: 0.00372 time model: 7.81154 acc: 185.55000
[epoch: 9, batch:    141] loss: 0.00349 time model: 9.11322 acc: 216.75000
[epoch: 9, batch:    161] loss: 0.00324 time model: 10.41609 acc: 248.35000
[epoch: 9, batch:    181] loss: 0.00309 time model: 11.71860 acc: 279.80000
[epoch: 9, batch:    201] loss: 0.00308 time model: 13.02152 acc: 310.95000
[epoch: 9, batch:    221] loss: 0.00296 time model: 14.32372 acc: 342.35000
[epoch: 9, batch:    241] loss: 0.00288 time model: 15.62649 acc: 373.70000
[epoch: 9, batch:    261] loss: 0.00276 time model: 16.92788 acc: 405.35000
[epoch: 9, batch:    281] loss: 0.00268 time model: 18.22925 acc: 436.95000
[epoch: 9, batch:    301] loss: 0.00265 time model: 19.53068 acc: 468.25000
[epoch: 9, batch:    321] loss: 0.00260 time model: 20.83295 acc: 499.70000
[epoch: 9, batch:    341] loss: 0.00255 time model: 22.13579 acc: 531.00000
[epoch: 9, batch:    361] loss: 0.00250 time model: 23.43975 acc: 562.60000
[epoch: 9, batch:    381] loss: 0.00256 time model: 24.74586 acc: 593.35000
[epoch: 9, batch:    401] loss: 0.00256 time model: 26.05135 acc: 624.40000
[epoch: 9, batch:    421] loss: 0.00258 time model: 27.35774 acc: 655.50000
[epoch: 9, batch:    441] loss: 0.00258 time model: 28.66361 acc: 686.75000
[epoch: 9, batch:    461] loss: 0.00256 time model: 29.96947 acc: 718.05000
[epoch: 9, batch:    481] loss: 0.00252 time model: 31.27476 acc: 749.65000
[epoch: 9, batch:    501] loss: 0.00257 time model: 32.58105 acc: 780.40000
[epoch: 9, batch:    521] loss: 0.00254 time model: 33.88568 acc: 811.95000
[epoch: 9, batch:    541] loss: 0.00252 time model: 35.19131 acc: 843.40000
[epoch: 9, batch:    561] loss: 0.00249 time model: 36.49770 acc: 874.95000
[epoch: 9, batch:    581] loss: 0.00245 time model: 37.80373 acc: 906.70000
[epoch: 9, batch:    601] loss: 0.00242 time model: 39.11003 acc: 938.30000
[epoch: 9, batch:    621] loss: 0.00240 time model: 40.41523 acc: 969.80000
[epoch: 9, batch:    641] loss: 0.00237 time model: 41.72028 acc: 1001.40000
[epoch: 9, batch:    661] loss: 0.00234 time model: 43.00618 acc: 1032.25000
[epoch: 9, batch:     21] loss: 0.00801 time model: 0.84595 acc: 29.85000
[epoch: 9, batch:     41] loss: 0.00784 time model: 1.69293 acc: 59.50000
[epoch: 9, batch:     61] loss: 0.00682 time model: 2.53985 acc: 89.85000
[epoch: 9, batch:     81] loss: 0.00734 time model: 3.38558 acc: 119.50000
epoch:9 train loss: 0.002343339871485435 train acc: 0.9782042170101871 valid loss: 0.0073362646445915315 valid acc: 0.9336437718277066
[epoch: 10, batch:     21] loss: 0.00152 time model: 1.30677 acc: 31.50000
[epoch: 10, batch:     41] loss: 0.00179 time model: 2.61400 acc: 62.75000
[epoch: 10, batch:     61] loss: 0.00178 time model: 3.92103 acc: 94.20000
[epoch: 10, batch:     81] loss: 0.00200 time model: 5.22713 acc: 125.30000
[epoch: 10, batch:    101] loss: 0.00182 time model: 6.53308 acc: 157.05000
[epoch: 10, batch:    121] loss: 0.00174 time model: 7.83945 acc: 188.60000
[epoch: 10, batch:    141] loss: 0.00173 time model: 9.14446 acc: 220.15000
[epoch: 10, batch:    161] loss: 0.00167 time model: 10.44963 acc: 251.65000
[epoch: 10, batch:    181] loss: 0.00160 time model: 11.75557 acc: 283.30000
[epoch: 10, batch:    201] loss: 0.00154 time model: 13.06233 acc: 314.95000
[epoch: 10, batch:    221] loss: 0.00151 time model: 14.36709 acc: 346.60000
[epoch: 10, batch:    241] loss: 0.00146 time model: 15.67368 acc: 378.40000
[epoch: 10, batch:    261] loss: 0.00144 time model: 16.97950 acc: 410.05000
[epoch: 10, batch:    281] loss: 0.00149 time model: 18.28519 acc: 441.35000
[epoch: 10, batch:    301] loss: 0.00151 time model: 19.59062 acc: 472.80000
[epoch: 10, batch:    321] loss: 0.00150 time model: 20.89633 acc: 504.30000
[epoch: 10, batch:    341] loss: 0.00148 time model: 22.20279 acc: 536.00000
[epoch: 10, batch:    361] loss: 0.00148 time model: 23.50906 acc: 567.55000
[epoch: 10, batch:    381] loss: 0.00152 time model: 24.81527 acc: 599.00000
[epoch: 10, batch:    401] loss: 0.00156 time model: 26.12108 acc: 630.30000
[epoch: 10, batch:    421] loss: 0.00178 time model: 27.42587 acc: 659.95000
[epoch: 10, batch:    441] loss: 0.00197 time model: 28.73139 acc: 690.10000
[epoch: 10, batch:    461] loss: 0.00200 time model: 30.03680 acc: 721.05000
[epoch: 10, batch:    481] loss: 0.00199 time model: 31.34234 acc: 752.45000
[epoch: 10, batch:    501] loss: 0.00201 time model: 32.64797 acc: 783.70000
[epoch: 10, batch:    521] loss: 0.00204 time model: 33.95345 acc: 814.70000
[epoch: 10, batch:    541] loss: 0.00203 time model: 35.25899 acc: 846.30000
[epoch: 10, batch:    561] loss: 0.00201 time model: 36.56604 acc: 877.90000
[epoch: 10, batch:    581] loss: 0.00201 time model: 37.86979 acc: 909.20000
[epoch: 10, batch:    601] loss: 0.00202 time model: 39.17239 acc: 940.40000
[epoch: 10, batch:    621] loss: 0.00203 time model: 40.47528 acc: 971.70000
[epoch: 10, batch:    641] loss: 0.00201 time model: 41.77876 acc: 1003.15000
[epoch: 10, batch:    661] loss: 0.00203 time model: 43.06201 acc: 1033.60000
[epoch: 10, batch:     21] loss: 0.01131 time model: 0.84167 acc: 28.90000
[epoch: 10, batch:     41] loss: 0.01139 time model: 1.68403 acc: 57.25000
[epoch: 10, batch:     61] loss: 0.01085 time model: 2.52630 acc: 86.35000
[epoch: 10, batch:     81] loss: 0.01026 time model: 3.36681 acc: 116.00000
epoch:10 train loss: 0.00202505562663629 train acc: 0.9794835347074153 valid loss: 0.010389240638583864 valid acc: 0.906092355452076
