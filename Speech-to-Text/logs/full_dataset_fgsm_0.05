[epoch: 1, batch:     20] loss: 0.08771 time model: 0.03981 acc: 0.07812
[epoch: 1, batch:     40] loss: 0.08024 time model: 0.03952 acc: 0.10547
[epoch: 1, batch:     60] loss: 0.07709 time model: 0.03946 acc: 0.13542
[epoch: 1, batch:     80] loss: 0.07566 time model: 0.03944 acc: 0.14023
[epoch: 1, batch:    100] loss: 0.07441 time model: 0.03942 acc: 0.14906
[epoch: 1, batch:    120] loss: 0.07322 time model: 0.03941 acc: 0.15911
[epoch: 1, batch:    140] loss: 0.07196 time model: 0.03942 acc: 0.17299
[epoch: 1, batch:    160] loss: 0.07135 time model: 0.03944 acc: 0.18086
[epoch: 1, batch:    180] loss: 0.07037 time model: 0.03945 acc: 0.19115
[epoch: 1, batch:    200] loss: 0.06953 time model: 0.03946 acc: 0.19953
[epoch: 1, batch:    220] loss: 0.06869 time model: 0.03946 acc: 0.20682
[epoch: 1, batch:    240] loss: 0.06797 time model: 0.03947 acc: 0.21367
[epoch: 1, batch:    260] loss: 0.06725 time model: 0.03947 acc: 0.22187
[epoch: 1, batch:    280] loss: 0.06674 time model: 0.03948 acc: 0.22935
[epoch: 1, batch:    300] loss: 0.06603 time model: 0.03948 acc: 0.23563
[epoch: 1, batch:    320] loss: 0.06543 time model: 0.03949 acc: 0.24248
[epoch: 1, batch:    340] loss: 0.06459 time model: 0.03949 acc: 0.25175
[epoch: 1, batch:    360] loss: 0.06392 time model: 0.03949 acc: 0.26016
[epoch: 1, batch:    380] loss: 0.06305 time model: 0.03948 acc: 0.27031
[epoch: 1, batch:    400] loss: 0.06228 time model: 0.03948 acc: 0.27727
[epoch: 1, batch:    420] loss: 0.06145 time model: 0.03947 acc: 0.28705
[epoch: 1, batch:    440] loss: 0.06058 time model: 0.03947 acc: 0.29744
[epoch: 1, batch:    460] loss: 0.05973 time model: 0.03947 acc: 0.30659
[epoch: 1, batch:    480] loss: 0.05890 time model: 0.03946 acc: 0.31576
[epoch: 1, batch:    500] loss: 0.05827 time model: 0.03946 acc: 0.32381
[epoch: 1, batch:    520] loss: 0.05748 time model: 0.03946 acc: 0.33197
[epoch: 1, batch:    540] loss: 0.05668 time model: 0.03945 acc: 0.34028
[epoch: 1, batch:    560] loss: 0.05595 time model: 0.03945 acc: 0.34738
[epoch: 1, batch:    580] loss: 0.05532 time model: 0.03945 acc: 0.35485
[epoch: 1, batch:    600] loss: 0.05453 time model: 0.03945 acc: 0.36380
[epoch: 1, batch:    620] loss: 0.05385 time model: 0.03944 acc: 0.37172
[epoch: 1, batch:    640] loss: 0.05323 time model: 0.03945 acc: 0.37822
[epoch: 1, batch:    660] loss: 0.05259 time model: 0.03946 acc: 0.38531
[epoch: 1, batch:     20] loss: 0.03897 time model: 0.02559 acc: 0.53906
[epoch: 1, batch:     40] loss: 0.03915 time model: 0.02558 acc: 0.52656
[epoch: 1, batch:     60] loss: 0.03838 time model: 0.02557 acc: 0.53854
[epoch: 1, batch:     80] loss: 0.03807 time model: 0.02556 acc: 0.54492
epoch:1 train loss: 0.05259403623808224 train acc: 0.38531153755034353 valid loss: 0.03828653273399273 valid acc: 0.5444315095071789
