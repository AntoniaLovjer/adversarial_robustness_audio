[epoch: 1, batch:     21] loss: 0.08121 time model: 1.30524 acc: 3.30000
[epoch: 1, batch:     41] loss: 0.07901 time model: 2.60901 acc: 6.55000
[epoch: 1, batch:     61] loss: 0.07813 time model: 3.91257 acc: 10.25000
[epoch: 1, batch:     81] loss: 0.07824 time model: 5.21658 acc: 12.35000
[epoch: 1, batch:    101] loss: 0.07787 time model: 6.51902 acc: 15.25000
[epoch: 1, batch:    121] loss: 0.07744 time model: 7.82210 acc: 18.25000
[epoch: 1, batch:    141] loss: 0.07704 time model: 9.12482 acc: 21.50000
[epoch: 1, batch:    161] loss: 0.07681 time model: 10.42811 acc: 24.70000
[epoch: 1, batch:    181] loss: 0.07655 time model: 11.73086 acc: 28.90000
[epoch: 1, batch:    201] loss: 0.07635 time model: 13.03342 acc: 32.90000
[epoch: 1, batch:    221] loss: 0.07592 time model: 14.33628 acc: 37.80000
[epoch: 1, batch:    241] loss: 0.07529 time model: 15.63905 acc: 43.05000
[epoch: 1, batch:    261] loss: 0.07522 time model: 16.94221 acc: 46.65000
[epoch: 1, batch:    281] loss: 0.07527 time model: 18.24485 acc: 49.35000
[epoch: 1, batch:    301] loss: 0.07513 time model: 19.54759 acc: 53.65000
[epoch: 1, batch:    321] loss: 0.07511 time model: 20.84970 acc: 57.30000
[epoch: 1, batch:    341] loss: 0.07484 time model: 22.15115 acc: 62.15000
[epoch: 1, batch:    361] loss: 0.07449 time model: 23.45321 acc: 67.90000
[epoch: 1, batch:    381] loss: 0.07459 time model: 24.75663 acc: 71.45000
[epoch: 1, batch:    401] loss: 0.07430 time model: 26.05913 acc: 78.00000
[epoch: 1, batch:    421] loss: 0.07369 time model: 27.36001 acc: 87.65000
[epoch: 1, batch:    441] loss: 0.07275 time model: 28.66150 acc: 100.75000
[epoch: 1, batch:    461] loss: 0.07283 time model: 29.96352 acc: 105.75000
[epoch: 1, batch:    481] loss: 0.07263 time model: 31.26502 acc: 112.10000
[epoch: 1, batch:    501] loss: 0.07226 time model: 32.56801 acc: 119.55000
[epoch: 1, batch:    521] loss: 0.07227 time model: 33.86939 acc: 124.60000
[epoch: 1, batch:    541] loss: 0.07223 time model: 35.17132 acc: 129.30000
[epoch: 1, batch:    561] loss: 0.07217 time model: 36.47373 acc: 135.20000
[epoch: 1, batch:    581] loss: 0.07190 time model: 37.77710 acc: 143.05000
[epoch: 1, batch:    601] loss: 0.07185 time model: 39.08014 acc: 149.20000
[epoch: 1, batch:    621] loss: 0.07202 time model: 40.38320 acc: 152.60000
[epoch: 1, batch:    641] loss: 0.07197 time model: 41.68604 acc: 157.70000
[epoch: 1, batch:    661] loss: 0.07191 time model: 42.97228 acc: 163.30000
[epoch: 1, batch:     21] loss: 0.07845 time model: 0.84394 acc: 4.70000
[epoch: 1, batch:     41] loss: 0.07912 time model: 1.68814 acc: 8.70000
[epoch: 1, batch:     61] loss: 0.07880 time model: 2.53265 acc: 13.30000
[epoch: 1, batch:     81] loss: 0.07885 time model: 3.37628 acc: 17.85000
epoch:1 train loss: 0.07190961527107056 train acc: 0.15475005922767116 valid loss: 0.07912043198440072 valid acc: 0.14008537058595266
[epoch: 2, batch:     21] loss: 0.06463 time model: 1.30650 acc: 7.95000
[epoch: 2, batch:     41] loss: 0.06507 time model: 2.61205 acc: 14.45000
[epoch: 2, batch:     61] loss: 0.06395 time model: 3.91762 acc: 23.35000
[epoch: 2, batch:     81] loss: 0.06386 time model: 5.22418 acc: 31.65000
[epoch: 2, batch:    101] loss: 0.06351 time model: 6.53048 acc: 40.55000
[epoch: 2, batch:    121] loss: 0.06322 time model: 7.83673 acc: 50.10000
[epoch: 2, batch:    141] loss: 0.06317 time model: 9.14317 acc: 58.45000
[epoch: 2, batch:    161] loss: 0.06233 time model: 10.44872 acc: 69.90000
[epoch: 2, batch:    181] loss: 0.06117 time model: 11.75385 acc: 82.85000
[epoch: 2, batch:    201] loss: 0.06021 time model: 13.05960 acc: 96.00000
[epoch: 2, batch:    221] loss: 0.05919 time model: 14.36543 acc: 109.80000
[epoch: 2, batch:    241] loss: 0.05807 time model: 15.67171 acc: 125.20000
[epoch: 2, batch:    261] loss: 0.05743 time model: 16.97801 acc: 139.05000
[epoch: 2, batch:    281] loss: 0.05667 time model: 18.28436 acc: 154.25000
[epoch: 2, batch:    301] loss: 0.05558 time model: 19.59097 acc: 170.50000
[epoch: 2, batch:    321] loss: 0.05434 time model: 20.89716 acc: 189.25000
[epoch: 2, batch:    341] loss: 0.05328 time model: 22.20275 acc: 208.55000
[epoch: 2, batch:    361] loss: 0.05246 time model: 23.50945 acc: 227.60000
[epoch: 2, batch:    381] loss: 0.05146 time model: 24.81662 acc: 248.45000
[epoch: 2, batch:    401] loss: 0.05060 time model: 26.12427 acc: 268.90000
[epoch: 2, batch:    421] loss: 0.04964 time model: 27.43138 acc: 290.45000
[epoch: 2, batch:    441] loss: 0.04861 time model: 28.73758 acc: 313.55000
[epoch: 2, batch:    461] loss: 0.04755 time model: 30.04436 acc: 337.55000
[epoch: 2, batch:    481] loss: 0.04638 time model: 31.35049 acc: 364.25000
[epoch: 2, batch:    501] loss: 0.04525 time model: 32.65761 acc: 391.30000
[epoch: 2, batch:    521] loss: 0.04451 time model: 33.96368 acc: 415.80000
[epoch: 2, batch:    541] loss: 0.04383 time model: 35.26969 acc: 439.90000
[epoch: 2, batch:    561] loss: 0.04296 time model: 36.57420 acc: 465.90000
[epoch: 2, batch:    581] loss: 0.04214 time model: 37.88135 acc: 491.75000
[epoch: 2, batch:    601] loss: 0.04124 time model: 39.18798 acc: 518.65000
[epoch: 2, batch:    621] loss: 0.04036 time model: 40.49415 acc: 546.35000
[epoch: 2, batch:    641] loss: 0.03942 time model: 41.80169 acc: 575.80000
[epoch: 2, batch:    661] loss: 0.03866 time model: 43.08886 acc: 602.50000
[epoch: 2, batch:     21] loss: 0.05170 time model: 0.84220 acc: 14.65000
[epoch: 2, batch:     41] loss: 0.05182 time model: 1.68462 acc: 28.65000
[epoch: 2, batch:     61] loss: 0.05224 time model: 2.52627 acc: 43.55000
[epoch: 2, batch:     81] loss: 0.05262 time model: 3.36880 acc: 57.20000
epoch:2 train loss: 0.03865741330621029 train acc: 0.5709547500592277 valid loss: 0.05293494828412548 valid acc: 0.4470314318975553
[epoch: 3, batch:     21] loss: 0.01118 time model: 1.30752 acc: 28.95000
[epoch: 3, batch:     41] loss: 0.01048 time model: 2.61564 acc: 58.60000
[epoch: 3, batch:     61] loss: 0.00995 time model: 3.92204 acc: 87.80000
[epoch: 3, batch:     81] loss: 0.01015 time model: 5.22832 acc: 116.20000
[epoch: 3, batch:    101] loss: 0.00968 time model: 6.53567 acc: 146.30000
[epoch: 3, batch:    121] loss: 0.00943 time model: 7.84233 acc: 176.25000
[epoch: 3, batch:    141] loss: 0.00906 time model: 9.14860 acc: 206.60000
[epoch: 3, batch:    161] loss: 0.00879 time model: 10.45204 acc: 236.55000
[epoch: 3, batch:    181] loss: 0.00914 time model: 11.75529 acc: 265.30000
[epoch: 3, batch:    201] loss: 0.00986 time model: 13.05783 acc: 292.05000
[epoch: 3, batch:    221] loss: 0.00983 time model: 14.36114 acc: 321.20000
[epoch: 3, batch:    241] loss: 0.00946 time model: 15.66482 acc: 351.90000
[epoch: 3, batch:    261] loss: 0.00941 time model: 16.96901 acc: 381.40000
[epoch: 3, batch:    281] loss: 0.00920 time model: 18.27382 acc: 411.50000
[epoch: 3, batch:    301] loss: 0.00910 time model: 19.57774 acc: 441.55000
[epoch: 3, batch:    321] loss: 0.00889 time model: 20.88266 acc: 471.65000
[epoch: 3, batch:    341] loss: 0.00866 time model: 22.18595 acc: 502.35000
[epoch: 3, batch:    361] loss: 0.00850 time model: 23.49148 acc: 532.65000
[epoch: 3, batch:    381] loss: 0.00840 time model: 24.79771 acc: 562.75000
[epoch: 3, batch:    401] loss: 0.00827 time model: 26.10241 acc: 593.00000
[epoch: 3, batch:    421] loss: 0.00814 time model: 27.40619 acc: 623.45000
[epoch: 3, batch:    441] loss: 0.00795 time model: 28.70903 acc: 654.30000
[epoch: 3, batch:    461] loss: 0.00781 time model: 30.01239 acc: 684.90000
[epoch: 3, batch:    481] loss: 0.00771 time model: 31.31630 acc: 715.25000
[epoch: 3, batch:    501] loss: 0.00764 time model: 32.62096 acc: 745.55000
[epoch: 3, batch:    521] loss: 0.00757 time model: 33.92400 acc: 775.85000
[epoch: 3, batch:    541] loss: 0.00746 time model: 35.22694 acc: 806.75000
[epoch: 3, batch:    561] loss: 0.00737 time model: 36.53025 acc: 837.60000
[epoch: 3, batch:    581] loss: 0.00726 time model: 37.83516 acc: 868.40000
[epoch: 3, batch:    601] loss: 0.00719 time model: 39.13815 acc: 898.95000
[epoch: 3, batch:    621] loss: 0.00713 time model: 40.44107 acc: 929.25000
[epoch: 3, batch:    641] loss: 0.00706 time model: 41.74721 acc: 959.95000
[epoch: 3, batch:    661] loss: 0.00706 time model: 43.03283 acc: 989.30000
[epoch: 3, batch:     21] loss: 0.03770 time model: 0.83652 acc: 19.30000
[epoch: 3, batch:     41] loss: 0.04094 time model: 1.67182 acc: 36.00000
[epoch: 3, batch:     61] loss: 0.04246 time model: 2.50881 acc: 52.85000
[epoch: 3, batch:     81] loss: 0.04215 time model: 3.34430 acc: 70.80000
epoch:3 train loss: 0.0070582434100806505 train acc: 0.9375029613835584 valid loss: 0.042457786511209156 valid acc: 0.5518044237485448
[epoch: 4, batch:     21] loss: 0.00502 time model: 1.30390 acc: 30.85000
[epoch: 4, batch:     41] loss: 0.00431 time model: 2.60673 acc: 61.65000
[epoch: 4, batch:     61] loss: 0.00457 time model: 3.91017 acc: 92.05000
[epoch: 4, batch:     81] loss: 0.00479 time model: 5.21238 acc: 122.45000
[epoch: 4, batch:    101] loss: 0.00484 time model: 6.51557 acc: 152.55000
[epoch: 4, batch:    121] loss: 0.00471 time model: 7.81859 acc: 183.35000
[epoch: 4, batch:    141] loss: 0.00465 time model: 9.12102 acc: 214.00000
[epoch: 4, batch:    161] loss: 0.00455 time model: 10.42418 acc: 244.75000
[epoch: 4, batch:    181] loss: 0.00450 time model: 11.72694 acc: 275.80000
[epoch: 4, batch:    201] loss: 0.00448 time model: 13.03019 acc: 306.50000
[epoch: 4, batch:    221] loss: 0.00455 time model: 14.33442 acc: 337.15000
[epoch: 4, batch:    241] loss: 0.00455 time model: 15.64106 acc: 368.15000
[epoch: 4, batch:    261] loss: 0.00456 time model: 16.94767 acc: 398.85000
[epoch: 4, batch:    281] loss: 0.00460 time model: 18.25382 acc: 429.05000
[epoch: 4, batch:    301] loss: 0.00456 time model: 19.55938 acc: 459.85000
[epoch: 4, batch:    321] loss: 0.00449 time model: 20.86462 acc: 491.00000
[epoch: 4, batch:    341] loss: 0.00452 time model: 22.17068 acc: 521.55000
[epoch: 4, batch:    361] loss: 0.00452 time model: 23.47607 acc: 552.20000
[epoch: 4, batch:    381] loss: 0.00444 time model: 24.78252 acc: 583.40000
[epoch: 4, batch:    401] loss: 0.00441 time model: 26.08900 acc: 614.25000
[epoch: 4, batch:    421] loss: 0.00437 time model: 27.39424 acc: 645.10000
[epoch: 4, batch:    441] loss: 0.00443 time model: 28.70001 acc: 675.35000
[epoch: 4, batch:    461] loss: 0.00440 time model: 30.00697 acc: 706.50000
[epoch: 4, batch:    481] loss: 0.00437 time model: 31.31304 acc: 737.20000
[epoch: 4, batch:    501] loss: 0.00435 time model: 32.61943 acc: 768.05000
[epoch: 4, batch:    521] loss: 0.00433 time model: 33.92570 acc: 798.70000
[epoch: 4, batch:    541] loss: 0.00434 time model: 35.23174 acc: 829.15000
[epoch: 4, batch:    561] loss: 0.00434 time model: 36.53822 acc: 859.80000
[epoch: 4, batch:    581] loss: 0.00432 time model: 37.84401 acc: 890.55000
[epoch: 4, batch:    601] loss: 0.00429 time model: 39.15071 acc: 921.60000
[epoch: 4, batch:    621] loss: 0.00428 time model: 40.45654 acc: 952.45000
[epoch: 4, batch:    641] loss: 0.00423 time model: 41.76482 acc: 983.80000
[epoch: 4, batch:    661] loss: 0.00421 time model: 43.05335 acc: 1013.95000
[epoch: 4, batch:     21] loss: 0.04856 time model: 0.84063 acc: 17.00000
[epoch: 4, batch:     41] loss: 0.04729 time model: 1.68318 acc: 34.70000
[epoch: 4, batch:     61] loss: 0.04549 time model: 2.52462 acc: 52.50000
[epoch: 4, batch:     81] loss: 0.04566 time model: 3.36610 acc: 69.90000
epoch:4 train loss: 0.00421258052539639 train acc: 0.9608623548922056 valid loss: 0.04585432546010164 valid acc: 0.5459837019790454
[epoch: 5, batch:     21] loss: 0.00343 time model: 1.30738 acc: 31.00000
[epoch: 5, batch:     41] loss: 0.00337 time model: 2.61657 acc: 62.10000
[epoch: 5, batch:     61] loss: 0.00295 time model: 3.92462 acc: 93.75000
[epoch: 5, batch:     81] loss: 0.00323 time model: 5.23206 acc: 124.30000
[epoch: 5, batch:    101] loss: 0.00333 time model: 6.53958 acc: 155.25000
[epoch: 5, batch:    121] loss: 0.00335 time model: 7.84641 acc: 186.15000
[epoch: 5, batch:    141] loss: 0.00328 time model: 9.15295 acc: 217.25000
[epoch: 5, batch:    161] loss: 0.00321 time model: 10.46064 acc: 248.40000
[epoch: 5, batch:    181] loss: 0.00322 time model: 11.76633 acc: 279.25000
[epoch: 5, batch:    201] loss: 0.00323 time model: 13.07322 acc: 310.20000
[epoch: 5, batch:    221] loss: 0.00328 time model: 14.37944 acc: 340.90000
[epoch: 5, batch:    241] loss: 0.00329 time model: 15.68608 acc: 371.70000
[epoch: 5, batch:    261] loss: 0.00343 time model: 16.99290 acc: 402.35000
[epoch: 5, batch:    281] loss: 0.00350 time model: 18.30010 acc: 432.95000
[epoch: 5, batch:    301] loss: 0.00357 time model: 19.60607 acc: 463.55000
[epoch: 5, batch:    321] loss: 0.00352 time model: 20.91316 acc: 494.60000
[epoch: 5, batch:    341] loss: 0.00348 time model: 22.22050 acc: 525.65000
[epoch: 5, batch:    361] loss: 0.00345 time model: 23.52766 acc: 556.65000
[epoch: 5, batch:    381] loss: 0.00343 time model: 24.83443 acc: 587.75000
[epoch: 5, batch:    401] loss: 0.00340 time model: 26.14141 acc: 618.80000
[epoch: 5, batch:    421] loss: 0.00336 time model: 27.44837 acc: 649.85000
[epoch: 5, batch:    441] loss: 0.00333 time model: 28.75339 acc: 681.10000
[epoch: 5, batch:    461] loss: 0.00330 time model: 30.05623 acc: 712.40000
[epoch: 5, batch:    481] loss: 0.00329 time model: 31.35937 acc: 743.40000
[epoch: 5, batch:    501] loss: 0.00330 time model: 32.66332 acc: 774.35000
[epoch: 5, batch:    521] loss: 0.00333 time model: 33.96751 acc: 805.10000
[epoch: 5, batch:    541] loss: 0.00331 time model: 35.27095 acc: 836.30000
[epoch: 5, batch:    561] loss: 0.00332 time model: 36.57571 acc: 867.10000
[epoch: 5, batch:    581] loss: 0.00330 time model: 37.87907 acc: 898.30000
[epoch: 5, batch:    601] loss: 0.00326 time model: 39.18229 acc: 929.75000
[epoch: 5, batch:    621] loss: 0.00322 time model: 40.48752 acc: 961.20000
[epoch: 5, batch:    641] loss: 0.00317 time model: 41.79211 acc: 993.00000
[epoch: 5, batch:    661] loss: 0.00314 time model: 43.07617 acc: 1023.70000
[epoch: 5, batch:     21] loss: 0.03406 time model: 0.83915 acc: 21.25000
[epoch: 5, batch:     41] loss: 0.03334 time model: 1.67716 acc: 42.85000
[epoch: 5, batch:     61] loss: 0.03196 time model: 2.51492 acc: 65.55000
[epoch: 5, batch:     81] loss: 0.03213 time model: 3.35132 acc: 87.15000
epoch:5 train loss: 0.0031379618112494724 train acc: 0.9701018715944089 valid loss: 0.032281030320732644 valid acc: 0.6802483507954986
[epoch: 6, batch:     21] loss: 0.00230 time model: 1.30440 acc: 31.40000
[epoch: 6, batch:     41] loss: 0.00227 time model: 2.60731 acc: 62.80000
[epoch: 6, batch:     61] loss: 0.00258 time model: 3.91165 acc: 93.90000
[epoch: 6, batch:     81] loss: 0.00296 time model: 5.21603 acc: 124.65000
[epoch: 6, batch:    101] loss: 0.00302 time model: 6.51927 acc: 155.55000
[epoch: 6, batch:    121] loss: 0.00310 time model: 7.82407 acc: 186.40000
[epoch: 6, batch:    141] loss: 0.00309 time model: 9.12675 acc: 217.30000
[epoch: 6, batch:    161] loss: 0.00360 time model: 10.42964 acc: 247.35000
[epoch: 6, batch:    181] loss: 0.00399 time model: 11.73438 acc: 277.05000
[epoch: 6, batch:    201] loss: 0.00401 time model: 13.03879 acc: 307.70000
[epoch: 6, batch:    221] loss: 0.00379 time model: 14.34306 acc: 339.40000
[epoch: 6, batch:    241] loss: 0.00372 time model: 15.64648 acc: 370.45000
[epoch: 6, batch:    261] loss: 0.00365 time model: 16.95102 acc: 401.80000
[epoch: 6, batch:    281] loss: 0.00366 time model: 18.25439 acc: 432.60000
[epoch: 6, batch:    301] loss: 0.00360 time model: 19.55905 acc: 463.85000
[epoch: 6, batch:    321] loss: 0.00349 time model: 20.86202 acc: 495.25000
[epoch: 6, batch:    341] loss: 0.00340 time model: 22.16562 acc: 526.70000
[epoch: 6, batch:    361] loss: 0.00339 time model: 23.46932 acc: 557.60000
[epoch: 6, batch:    381] loss: 0.00338 time model: 24.77414 acc: 588.70000
[epoch: 6, batch:    401] loss: 0.00333 time model: 26.07835 acc: 619.95000
[epoch: 6, batch:    421] loss: 0.00325 time model: 27.38262 acc: 651.45000
[epoch: 6, batch:    441] loss: 0.00318 time model: 28.68750 acc: 683.10000
[epoch: 6, batch:    461] loss: 0.00315 time model: 29.99202 acc: 714.45000
[epoch: 6, batch:    481] loss: 0.00313 time model: 31.29693 acc: 745.80000
[epoch: 6, batch:    501] loss: 0.00310 time model: 32.60090 acc: 777.05000
[epoch: 6, batch:    521] loss: 0.00304 time model: 33.90844 acc: 808.50000
[epoch: 6, batch:    541] loss: 0.00299 time model: 35.21789 acc: 840.10000
[epoch: 6, batch:    561] loss: 0.00293 time model: 36.52527 acc: 871.90000
[epoch: 6, batch:    581] loss: 0.00294 time model: 37.83421 acc: 903.10000
[epoch: 6, batch:    601] loss: 0.00291 time model: 39.14147 acc: 934.40000
[epoch: 6, batch:    621] loss: 0.00289 time model: 40.44854 acc: 965.70000
[epoch: 6, batch:    641] loss: 0.00286 time model: 41.75546 acc: 997.35000
[epoch: 6, batch:    661] loss: 0.00283 time model: 43.04364 acc: 1027.95000
[epoch: 6, batch:     21] loss: 0.02828 time model: 0.84379 acc: 22.80000
[epoch: 6, batch:     41] loss: 0.02586 time model: 1.68774 acc: 47.65000
[epoch: 6, batch:     61] loss: 0.02518 time model: 2.53192 acc: 71.95000
[epoch: 6, batch:     81] loss: 0.02579 time model: 3.37518 acc: 95.00000
epoch:6 train loss: 0.0028307766170615808 train acc: 0.9741293532338309 valid loss: 0.025781007980162383 valid acc: 0.7427240977881258
[epoch: 7, batch:     21] loss: 0.00226 time model: 1.30784 acc: 31.45000
[epoch: 7, batch:     41] loss: 0.00185 time model: 2.61511 acc: 62.95000
[epoch: 7, batch:     61] loss: 0.00161 time model: 3.92361 acc: 94.65000
[epoch: 7, batch:     81] loss: 0.00167 time model: 5.23109 acc: 126.15000
[epoch: 7, batch:    101] loss: 0.00179 time model: 6.53868 acc: 157.45000
[epoch: 7, batch:    121] loss: 0.00179 time model: 7.84683 acc: 188.75000
[epoch: 7, batch:    141] loss: 0.00183 time model: 9.15516 acc: 220.15000
[epoch: 7, batch:    161] loss: 0.00192 time model: 10.46304 acc: 251.20000
[epoch: 7, batch:    181] loss: 0.00196 time model: 11.77276 acc: 282.50000
[epoch: 7, batch:    201] loss: 0.00202 time model: 13.08050 acc: 313.65000
[epoch: 7, batch:    221] loss: 0.00202 time model: 14.38859 acc: 345.10000
[epoch: 7, batch:    241] loss: 0.00200 time model: 15.69454 acc: 376.55000
[epoch: 7, batch:    261] loss: 0.00201 time model: 16.99937 acc: 407.90000
[epoch: 7, batch:    281] loss: 0.00196 time model: 18.30412 acc: 439.60000
[epoch: 7, batch:    301] loss: 0.00203 time model: 19.61003 acc: 470.70000
[epoch: 7, batch:    321] loss: 0.00201 time model: 20.91569 acc: 502.30000
[epoch: 7, batch:    341] loss: 0.00197 time model: 22.22250 acc: 534.05000
[epoch: 7, batch:    361] loss: 0.00195 time model: 23.52724 acc: 565.60000
[epoch: 7, batch:    381] loss: 0.00193 time model: 24.83132 acc: 597.15000
[epoch: 7, batch:    401] loss: 0.00202 time model: 26.13585 acc: 627.85000
[epoch: 7, batch:    421] loss: 0.00213 time model: 27.44207 acc: 658.60000
[epoch: 7, batch:    441] loss: 0.00218 time model: 28.74785 acc: 689.45000
[epoch: 7, batch:    461] loss: 0.00218 time model: 30.05612 acc: 720.55000
[epoch: 7, batch:    481] loss: 0.00224 time model: 31.36438 acc: 751.60000
[epoch: 7, batch:    501] loss: 0.00226 time model: 32.67192 acc: 782.60000
[epoch: 7, batch:    521] loss: 0.00229 time model: 33.98049 acc: 813.80000
[epoch: 7, batch:    541] loss: 0.00228 time model: 35.28766 acc: 845.25000
[epoch: 7, batch:    561] loss: 0.00226 time model: 36.59506 acc: 876.75000
[epoch: 7, batch:    581] loss: 0.00224 time model: 37.90309 acc: 908.20000
[epoch: 7, batch:    601] loss: 0.00219 time model: 39.21030 acc: 940.05000
[epoch: 7, batch:    621] loss: 0.00219 time model: 40.51706 acc: 971.30000
[epoch: 7, batch:    641] loss: 0.00216 time model: 41.82407 acc: 1002.85000
[epoch: 7, batch:    661] loss: 0.00215 time model: 43.11192 acc: 1033.55000
[epoch: 7, batch:     21] loss: 0.03187 time model: 0.84294 acc: 23.00000
[epoch: 7, batch:     41] loss: 0.03186 time model: 1.68648 acc: 45.65000
[epoch: 7, batch:     61] loss: 0.03234 time model: 2.52982 acc: 68.30000
[epoch: 7, batch:     81] loss: 0.03246 time model: 3.37180 acc: 90.80000
epoch:7 train loss: 0.0021512414343095566 train acc: 0.9794361525704809 valid loss: 0.03258817968185345 valid acc: 0.7105161039968956
[epoch: 8, batch:     21] loss: 0.00130 time model: 1.30622 acc: 31.70000
[epoch: 8, batch:     41] loss: 0.00154 time model: 2.61000 acc: 63.15000
[epoch: 8, batch:     61] loss: 0.00155 time model: 3.91466 acc: 94.70000
[epoch: 8, batch:     81] loss: 0.00156 time model: 5.21909 acc: 126.10000
[epoch: 8, batch:    101] loss: 0.00161 time model: 6.52327 acc: 157.65000
[epoch: 8, batch:    121] loss: 0.00179 time model: 7.82788 acc: 188.75000
[epoch: 8, batch:    141] loss: 0.00179 time model: 9.13196 acc: 220.20000
[epoch: 8, batch:    161] loss: 0.00173 time model: 10.43662 acc: 251.75000
[epoch: 8, batch:    181] loss: 0.00173 time model: 11.73946 acc: 283.35000
[epoch: 8, batch:    201] loss: 0.00177 time model: 13.04232 acc: 314.65000
[epoch: 8, batch:    221] loss: 0.00185 time model: 14.34536 acc: 345.80000
[epoch: 8, batch:    241] loss: 0.00188 time model: 15.64848 acc: 377.05000
[epoch: 8, batch:    261] loss: 0.00189 time model: 16.95148 acc: 408.40000
[epoch: 8, batch:    281] loss: 0.00187 time model: 18.25468 acc: 439.85000
[epoch: 8, batch:    301] loss: 0.00187 time model: 19.55784 acc: 471.20000
[epoch: 8, batch:    321] loss: 0.00182 time model: 20.86245 acc: 502.85000
[epoch: 8, batch:    341] loss: 0.00181 time model: 22.16569 acc: 534.15000
[epoch: 8, batch:    361] loss: 0.00181 time model: 23.47052 acc: 565.45000
[epoch: 8, batch:    381] loss: 0.00182 time model: 24.77490 acc: 596.90000
[epoch: 8, batch:    401] loss: 0.00181 time model: 26.07934 acc: 628.30000
[epoch: 8, batch:    421] loss: 0.00186 time model: 27.38328 acc: 659.50000
[epoch: 8, batch:    441] loss: 0.00184 time model: 28.68883 acc: 691.05000
[epoch: 8, batch:    461] loss: 0.00184 time model: 29.99349 acc: 722.55000
[epoch: 8, batch:    481] loss: 0.00181 time model: 31.29769 acc: 754.25000
[epoch: 8, batch:    501] loss: 0.00181 time model: 32.60196 acc: 785.60000
[epoch: 8, batch:    521] loss: 0.00181 time model: 33.90757 acc: 817.15000
[epoch: 8, batch:    541] loss: 0.00181 time model: 35.21369 acc: 848.55000
[epoch: 8, batch:    561] loss: 0.00180 time model: 36.52126 acc: 880.15000
[epoch: 8, batch:    581] loss: 0.00180 time model: 37.82729 acc: 911.65000
[epoch: 8, batch:    601] loss: 0.00179 time model: 39.13092 acc: 943.15000
[epoch: 8, batch:    621] loss: 0.00178 time model: 40.43572 acc: 974.70000
[epoch: 8, batch:    641] loss: 0.00177 time model: 41.73938 acc: 1006.10000
[epoch: 8, batch:    661] loss: 0.00178 time model: 43.02344 acc: 1036.85000
[epoch: 8, batch:     21] loss: 0.02318 time model: 0.83837 acc: 25.00000
[epoch: 8, batch:     41] loss: 0.02324 time model: 1.67713 acc: 49.70000
[epoch: 8, batch:     61] loss: 0.02331 time model: 2.51569 acc: 73.85000
[epoch: 8, batch:     81] loss: 0.02304 time model: 3.35249 acc: 98.45000
epoch:8 train loss: 0.00177765514104111 train acc: 0.9825633736081497 valid loss: 0.023033899591558424 valid acc: 0.7694994179278231
[epoch: 9, batch:     21] loss: 0.00142 time model: 1.30263 acc: 31.70000
[epoch: 9, batch:     41] loss: 0.00141 time model: 2.60713 acc: 63.15000
[epoch: 9, batch:     61] loss: 0.00131 time model: 3.91118 acc: 94.95000
[epoch: 9, batch:     81] loss: 0.00134 time model: 5.21612 acc: 126.40000
[epoch: 9, batch:    101] loss: 0.00150 time model: 6.52405 acc: 157.65000
[epoch: 9, batch:    121] loss: 0.00150 time model: 7.83226 acc: 189.25000
[epoch: 9, batch:    141] loss: 0.00151 time model: 9.13948 acc: 220.70000
[epoch: 9, batch:    161] loss: 0.00141 time model: 10.44784 acc: 252.50000
[epoch: 9, batch:    181] loss: 0.00148 time model: 11.75451 acc: 283.80000
[epoch: 9, batch:    201] loss: 0.00146 time model: 13.06348 acc: 315.45000
[epoch: 9, batch:    221] loss: 0.00145 time model: 14.37123 acc: 347.05000
[epoch: 9, batch:    241] loss: 0.00145 time model: 15.67894 acc: 378.60000
[epoch: 9, batch:    261] loss: 0.00148 time model: 16.98579 acc: 410.05000
[epoch: 9, batch:    281] loss: 0.00156 time model: 18.29347 acc: 441.20000
[epoch: 9, batch:    301] loss: 0.00158 time model: 19.60155 acc: 472.55000
[epoch: 9, batch:    321] loss: 0.00159 time model: 20.90976 acc: 503.80000
[epoch: 9, batch:    341] loss: 0.00156 time model: 22.21824 acc: 535.40000
[epoch: 9, batch:    361] loss: 0.00165 time model: 23.52690 acc: 566.45000
[epoch: 9, batch:    381] loss: 0.00170 time model: 24.83489 acc: 597.60000
[epoch: 9, batch:    401] loss: 0.00173 time model: 26.14320 acc: 628.80000
[epoch: 9, batch:    421] loss: 0.00171 time model: 27.45144 acc: 660.50000
[epoch: 9, batch:    441] loss: 0.00171 time model: 28.75906 acc: 692.00000
[epoch: 9, batch:    461] loss: 0.00171 time model: 30.06794 acc: 723.45000
[epoch: 9, batch:    481] loss: 0.00172 time model: 31.37495 acc: 754.65000
[epoch: 9, batch:    501] loss: 0.00171 time model: 32.68279 acc: 786.25000
[epoch: 9, batch:    521] loss: 0.00168 time model: 33.99006 acc: 818.00000
[epoch: 9, batch:    541] loss: 0.00168 time model: 35.29748 acc: 849.45000
[epoch: 9, batch:    561] loss: 0.00166 time model: 36.60481 acc: 881.00000
[epoch: 9, batch:    581] loss: 0.00167 time model: 37.91373 acc: 912.30000
[epoch: 9, batch:    601] loss: 0.00165 time model: 39.22204 acc: 944.00000
[epoch: 9, batch:    621] loss: 0.00165 time model: 40.52926 acc: 975.65000
[epoch: 9, batch:    641] loss: 0.00168 time model: 41.83685 acc: 1006.75000
[epoch: 9, batch:    661] loss: 0.00166 time model: 43.12531 acc: 1037.75000
[epoch: 9, batch:     21] loss: 0.01454 time model: 0.84433 acc: 27.85000
[epoch: 9, batch:     41] loss: 0.01621 time model: 1.68906 acc: 54.50000
[epoch: 9, batch:     61] loss: 0.01533 time model: 2.53320 acc: 82.35000
[epoch: 9, batch:     81] loss: 0.01570 time model: 3.37640 acc: 109.40000
epoch:9 train loss: 0.0016606318513079294 train acc: 0.9834162520729685 valid loss: 0.015779337421100086 valid acc: 0.8548700038804812
[epoch: 10, batch:     21] loss: 0.00149 time model: 1.30766 acc: 31.50000
[epoch: 10, batch:     41] loss: 0.00151 time model: 2.61517 acc: 63.05000
[epoch: 10, batch:     61] loss: 0.00180 time model: 3.92366 acc: 94.30000
[epoch: 10, batch:     81] loss: 0.00183 time model: 5.23156 acc: 125.75000
[epoch: 10, batch:    101] loss: 0.00164 time model: 6.53973 acc: 157.50000
[epoch: 10, batch:    121] loss: 0.00158 time model: 7.84807 acc: 189.05000
[epoch: 10, batch:    141] loss: 0.00156 time model: 9.15633 acc: 220.50000
[epoch: 10, batch:    161] loss: 0.00154 time model: 10.46369 acc: 252.10000
[epoch: 10, batch:    181] loss: 0.00154 time model: 11.77060 acc: 283.65000
[epoch: 10, batch:    201] loss: 0.00151 time model: 13.07740 acc: 315.40000
[epoch: 10, batch:    221] loss: 0.00147 time model: 14.38481 acc: 347.10000
[epoch: 10, batch:    241] loss: 0.00144 time model: 15.69262 acc: 378.80000
[epoch: 10, batch:    261] loss: 0.00144 time model: 17.00096 acc: 410.40000
[epoch: 10, batch:    281] loss: 0.00142 time model: 18.30821 acc: 442.00000
[epoch: 10, batch:    301] loss: 0.00142 time model: 19.61514 acc: 473.55000
[epoch: 10, batch:    321] loss: 0.00138 time model: 20.91829 acc: 505.25000
[epoch: 10, batch:    341] loss: 0.00136 time model: 22.22175 acc: 536.95000
[epoch: 10, batch:    361] loss: 0.00134 time model: 23.52439 acc: 568.75000
[epoch: 10, batch:    381] loss: 0.00136 time model: 24.82761 acc: 600.20000
[epoch: 10, batch:    401] loss: 0.00140 time model: 26.13056 acc: 631.55000
[epoch: 10, batch:    421] loss: 0.00141 time model: 27.43363 acc: 663.10000
[epoch: 10, batch:    441] loss: 0.00139 time model: 28.73622 acc: 694.80000
[epoch: 10, batch:    461] loss: 0.00138 time model: 30.03938 acc: 726.60000
[epoch: 10, batch:    481] loss: 0.00140 time model: 31.34192 acc: 758.10000
[epoch: 10, batch:    501] loss: 0.00141 time model: 32.64460 acc: 789.70000
[epoch: 10, batch:    521] loss: 0.00140 time model: 33.94756 acc: 821.30000
[epoch: 10, batch:    541] loss: 0.00142 time model: 35.25061 acc: 852.70000
[epoch: 10, batch:    561] loss: 0.00145 time model: 36.55429 acc: 884.10000
[epoch: 10, batch:    581] loss: 0.00144 time model: 37.85714 acc: 915.70000
[epoch: 10, batch:    601] loss: 0.00143 time model: 39.15995 acc: 947.30000
[epoch: 10, batch:    621] loss: 0.00144 time model: 40.46311 acc: 978.80000
[epoch: 10, batch:    641] loss: 0.00148 time model: 41.76592 acc: 1010.05000
[epoch: 10, batch:    661] loss: 0.00149 time model: 43.04874 acc: 1040.75000
[epoch: 10, batch:     21] loss: 0.00638 time model: 0.83989 acc: 30.30000
[epoch: 10, batch:     41] loss: 0.00590 time model: 1.67986 acc: 60.65000
[epoch: 10, batch:     61] loss: 0.00621 time model: 2.52057 acc: 90.00000
[epoch: 10, batch:     81] loss: 0.00624 time model: 3.36061 acc: 120.00000
epoch:10 train loss: 0.0014861015912283938 train acc: 0.986259180289031 valid loss: 0.006343400979694304 valid acc: 0.9371362048894063
