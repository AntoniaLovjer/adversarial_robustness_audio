[epoch: 1, batch:     21] loss: 0.07295 time model: 0.69672 acc: 5.25000
[epoch: 1, batch:     41] loss: 0.06736 time model: 1.35968 acc: 12.60000
[epoch: 1, batch:     61] loss: 0.06613 time model: 2.02003 acc: 20.80000
[epoch: 1, batch:     81] loss: 0.06590 time model: 2.68046 acc: 28.70000
[epoch: 1, batch:    101] loss: 0.06493 time model: 3.33946 acc: 38.35000
[epoch: 1, batch:    121] loss: 0.06445 time model: 3.99793 acc: 47.05000
[epoch: 1, batch:    141] loss: 0.06332 time model: 4.65579 acc: 58.45000
[epoch: 1, batch:    161] loss: 0.06317 time model: 5.31271 acc: 68.15000
[epoch: 1, batch:     21] loss: 0.07398 time model: 0.69250 acc: 5.05000
[epoch: 1, batch:     41] loss: 0.07090 time model: 1.35087 acc: 10.95000
[epoch: 1, batch:     61] loss: 0.06926 time model: 2.00826 acc: 17.05000
[epoch: 1, batch:     81] loss: 0.06774 time model: 2.66544 acc: 24.05000
[epoch: 1, batch:    101] loss: 0.06706 time model: 3.32231 acc: 31.45000
[epoch: 1, batch:    121] loss: 0.06596 time model: 3.97762 acc: 40.95000
[epoch: 1, batch:    141] loss: 0.06516 time model: 4.63258 acc: 50.00000
[epoch: 1, batch:    161] loss: 0.06408 time model: 5.28798 acc: 61.00000
[epoch: 1, batch:    181] loss: 0.06306 time model: 5.94295 acc: 73.30000
[epoch: 1, batch:    201] loss: 0.06178 time model: 6.59815 acc: 87.45000
[epoch: 1, batch:    221] loss: 0.06088 time model: 7.25367 acc: 100.40000
[epoch: 1, batch:    241] loss: 0.05960 time model: 7.90910 acc: 115.40000
[epoch: 1, batch:    261] loss: 0.05803 time model: 8.56408 acc: 133.60000
[epoch: 1, batch:    281] loss: 0.05662 time model: 9.21984 acc: 152.10000
[epoch: 1, batch:    301] loss: 0.05507 time model: 9.87529 acc: 172.95000
[epoch: 1, batch:    321] loss: 0.05402 time model: 10.53068 acc: 191.75000
[epoch: 1, batch:    341] loss: 0.05301 time model: 11.18542 acc: 211.05000
[epoch: 1, batch:    361] loss: 0.05178 time model: 11.83974 acc: 232.30000
[epoch: 1, batch:    381] loss: 0.05053 time model: 12.49579 acc: 254.60000
[epoch: 1, batch:    401] loss: 0.04949 time model: 13.15074 acc: 276.25000
[epoch: 1, batch:    421] loss: 0.04836 time model: 13.80604 acc: 298.80000
[epoch: 1, batch:    441] loss: 0.04727 time model: 14.46111 acc: 322.70000
[epoch: 1, batch:    461] loss: 0.04624 time model: 15.11631 acc: 346.75000
[epoch: 1, batch:    481] loss: 0.04519 time model: 15.77218 acc: 370.90000
[epoch: 1, batch:    501] loss: 0.04415 time model: 16.42735 acc: 396.40000
[epoch: 1, batch:    521] loss: 0.04333 time model: 17.08370 acc: 420.45000
[epoch: 1, batch:    541] loss: 0.04256 time model: 17.73826 acc: 445.40000
[epoch: 1, batch:    561] loss: 0.04174 time model: 18.39393 acc: 470.40000
[epoch: 1, batch:    581] loss: 0.04095 time model: 19.04946 acc: 495.85000
[epoch: 1, batch:    601] loss: 0.04019 time model: 19.70459 acc: 521.75000
[epoch: 1, batch:    621] loss: 0.03951 time model: 20.35973 acc: 547.55000
[epoch: 1, batch:    641] loss: 0.03889 time model: 21.01525 acc: 572.90000
[epoch: 1, batch:    661] loss: 0.03828 time model: 21.66050 acc: 598.00000
[epoch: 1, batch:     21] loss: 0.02703 time model: 0.20908 acc: 22.55000
[epoch: 1, batch:     41] loss: 0.02429 time model: 0.41592 acc: 46.80000
[epoch: 1, batch:     61] loss: 0.02363 time model: 0.62267 acc: 70.95000
[epoch: 1, batch:     81] loss: 0.02376 time model: 0.82949 acc: 94.40000
epoch:1 train loss: 0.03827961743287468 train acc: 0.5666903577351339 valid loss: 0.023795567155115632 valid acc: 0.7384555684904929
[epoch: 2, batch:     21] loss: 0.01788 time model: 0.65785 acc: 26.05000
[epoch: 2, batch:     41] loss: 0.01659 time model: 1.31364 acc: 52.60000
[epoch: 2, batch:     61] loss: 0.01587 time model: 1.97005 acc: 79.70000
[epoch: 2, batch:     81] loss: 0.01566 time model: 2.62601 acc: 106.80000
[epoch: 2, batch:    101] loss: 0.01546 time model: 3.28178 acc: 134.10000
[epoch: 2, batch:    121] loss: 0.01539 time model: 3.93740 acc: 160.70000
[epoch: 2, batch:    141] loss: 0.01519 time model: 4.59300 acc: 187.75000
[epoch: 2, batch:    161] loss: 0.01530 time model: 5.24843 acc: 214.15000
[epoch: 2, batch:    181] loss: 0.01538 time model: 5.90415 acc: 240.85000
[epoch: 2, batch:    201] loss: 0.01531 time model: 6.55976 acc: 267.75000
[epoch: 2, batch:    221] loss: 0.01524 time model: 7.21468 acc: 294.45000
[epoch: 2, batch:    241] loss: 0.01516 time model: 7.87101 acc: 321.70000
[epoch: 2, batch:    261] loss: 0.01502 time model: 8.52722 acc: 349.05000
[epoch: 2, batch:    281] loss: 0.01469 time model: 9.18359 acc: 377.50000
[epoch: 2, batch:    301] loss: 0.01460 time model: 9.84013 acc: 404.95000
[epoch: 2, batch:    321] loss: 0.01473 time model: 10.49721 acc: 431.00000
[epoch: 2, batch:    341] loss: 0.01461 time model: 11.15455 acc: 458.65000
[epoch: 2, batch:    361] loss: 0.01450 time model: 11.81300 acc: 486.25000
[epoch: 2, batch:    381] loss: 0.01436 time model: 12.46989 acc: 514.20000
[epoch: 2, batch:    401] loss: 0.01435 time model: 13.12711 acc: 541.30000
[epoch: 2, batch:    421] loss: 0.01420 time model: 13.78407 acc: 569.85000
[epoch: 2, batch:    441] loss: 0.01415 time model: 14.44079 acc: 597.70000
[epoch: 2, batch:    461] loss: 0.01404 time model: 15.09690 acc: 625.00000
[epoch: 2, batch:    481] loss: 0.01394 time model: 15.75272 acc: 652.95000
[epoch: 2, batch:    501] loss: 0.01382 time model: 16.40914 acc: 681.35000
[epoch: 2, batch:    521] loss: 0.01375 time model: 17.06535 acc: 709.50000
[epoch: 2, batch:    541] loss: 0.01366 time model: 17.72097 acc: 738.10000
[epoch: 2, batch:    561] loss: 0.01364 time model: 18.37711 acc: 765.55000
[epoch: 2, batch:    581] loss: 0.01357 time model: 19.03384 acc: 793.50000
[epoch: 2, batch:    601] loss: 0.01347 time model: 19.69072 acc: 821.80000
[epoch: 2, batch:    621] loss: 0.01339 time model: 20.34677 acc: 850.25000
[epoch: 2, batch:    641] loss: 0.01332 time model: 21.00251 acc: 878.45000
[epoch: 2, batch:    661] loss: 0.01326 time model: 21.64862 acc: 905.70000
[epoch: 2, batch:     21] loss: 0.01771 time model: 0.20910 acc: 25.90000
[epoch: 2, batch:     41] loss: 0.01855 time model: 0.41536 acc: 51.85000
[epoch: 2, batch:     61] loss: 0.01919 time model: 0.62209 acc: 77.75000
[epoch: 2, batch:     81] loss: 0.01871 time model: 0.82860 acc: 103.85000
epoch:2 train loss: 0.013258647075678833 train acc: 0.8582800284292822 valid loss: 0.018921883087959408 valid acc: 0.810244470314319
[epoch: 3, batch:     21] loss: 0.00794 time model: 0.65946 acc: 29.40000
[epoch: 3, batch:     41] loss: 0.00881 time model: 1.31903 acc: 58.05000
[epoch: 3, batch:     61] loss: 0.00905 time model: 1.97912 acc: 86.30000
[epoch: 3, batch:     81] loss: 0.00952 time model: 2.63904 acc: 114.65000
[epoch: 3, batch:    101] loss: 0.00967 time model: 3.29887 acc: 143.55000
[epoch: 3, batch:    121] loss: 0.00993 time model: 3.95737 acc: 171.65000
[epoch: 3, batch:    141] loss: 0.01019 time model: 4.61655 acc: 199.40000
[epoch: 3, batch:    161] loss: 0.00992 time model: 5.27567 acc: 228.70000
[epoch: 3, batch:    181] loss: 0.01014 time model: 5.93429 acc: 256.85000
[epoch: 3, batch:    201] loss: 0.01007 time model: 6.59325 acc: 285.50000
[epoch: 3, batch:    221] loss: 0.00996 time model: 7.25262 acc: 314.65000
[epoch: 3, batch:    241] loss: 0.01000 time model: 7.91143 acc: 343.40000
[epoch: 3, batch:    261] loss: 0.01004 time model: 8.57024 acc: 371.65000
[epoch: 3, batch:    281] loss: 0.01004 time model: 9.22874 acc: 400.05000
[epoch: 3, batch:    301] loss: 0.00996 time model: 9.88812 acc: 429.30000
[epoch: 3, batch:    321] loss: 0.00985 time model: 10.54736 acc: 458.75000
[epoch: 3, batch:    341] loss: 0.00990 time model: 11.20599 acc: 487.05000
[epoch: 3, batch:    361] loss: 0.00994 time model: 11.86532 acc: 515.55000
[epoch: 3, batch:    381] loss: 0.00988 time model: 12.52506 acc: 544.45000
[epoch: 3, batch:    401] loss: 0.00983 time model: 13.18542 acc: 573.35000
[epoch: 3, batch:    421] loss: 0.00983 time model: 13.84426 acc: 602.20000
[epoch: 3, batch:    441] loss: 0.00983 time model: 14.50320 acc: 630.75000
[epoch: 3, batch:    461] loss: 0.00980 time model: 15.16310 acc: 659.80000
[epoch: 3, batch:    481] loss: 0.00982 time model: 15.82219 acc: 688.45000
[epoch: 3, batch:    501] loss: 0.00973 time model: 16.48148 acc: 717.85000
[epoch: 3, batch:    521] loss: 0.00972 time model: 17.14175 acc: 746.65000
[epoch: 3, batch:    541] loss: 0.00971 time model: 17.80160 acc: 775.45000
[epoch: 3, batch:    561] loss: 0.00961 time model: 18.46178 acc: 805.20000
[epoch: 3, batch:    581] loss: 0.00959 time model: 19.12163 acc: 834.00000
[epoch: 3, batch:    601] loss: 0.00952 time model: 19.78229 acc: 863.40000
[epoch: 3, batch:    621] loss: 0.00950 time model: 20.44090 acc: 892.75000
[epoch: 3, batch:    641] loss: 0.00949 time model: 21.09989 acc: 921.15000
[epoch: 3, batch:    661] loss: 0.00949 time model: 21.74961 acc: 948.95000
[epoch: 3, batch:     21] loss: 0.01485 time model: 0.21042 acc: 26.45000
[epoch: 3, batch:     41] loss: 0.01470 time model: 0.41799 acc: 53.10000
[epoch: 3, batch:     61] loss: 0.01424 time model: 0.62678 acc: 80.35000
[epoch: 3, batch:     81] loss: 0.01389 time model: 0.83429 acc: 108.05000
epoch:3 train loss: 0.009492094063894412 train acc: 0.8992655768775172 valid loss: 0.013944736980031893 valid acc: 0.8443927046953822
[epoch: 4, batch:     21] loss: 0.00809 time model: 0.65997 acc: 29.15000
[epoch: 4, batch:     41] loss: 0.00822 time model: 1.32030 acc: 58.15000
[epoch: 4, batch:     61] loss: 0.00865 time model: 1.97981 acc: 87.00000
[epoch: 4, batch:     81] loss: 0.00856 time model: 2.63968 acc: 116.35000
[epoch: 4, batch:    101] loss: 0.00819 time model: 3.30025 acc: 146.15000
[epoch: 4, batch:    121] loss: 0.00816 time model: 3.96061 acc: 175.15000
[epoch: 4, batch:    141] loss: 0.00817 time model: 4.62094 acc: 204.55000
[epoch: 4, batch:    161] loss: 0.00786 time model: 5.28051 acc: 234.75000
[epoch: 4, batch:    181] loss: 0.00758 time model: 5.94036 acc: 265.00000
[epoch: 4, batch:    201] loss: 0.00753 time model: 6.60092 acc: 294.50000
[epoch: 4, batch:    221] loss: 0.00751 time model: 7.26097 acc: 324.05000
[epoch: 4, batch:    241] loss: 0.00750 time model: 7.92142 acc: 353.90000
[epoch: 4, batch:    261] loss: 0.00742 time model: 8.58199 acc: 383.35000
[epoch: 4, batch:    281] loss: 0.00745 time model: 9.24131 acc: 412.55000
[epoch: 4, batch:    301] loss: 0.00748 time model: 9.90085 acc: 442.10000
[epoch: 4, batch:    321] loss: 0.00762 time model: 10.56020 acc: 470.85000
[epoch: 4, batch:    341] loss: 0.00775 time model: 11.21940 acc: 499.80000
[epoch: 4, batch:    361] loss: 0.00776 time model: 11.87922 acc: 529.05000
[epoch: 4, batch:    381] loss: 0.00778 time model: 12.53887 acc: 558.35000
[epoch: 4, batch:    401] loss: 0.00776 time model: 13.19846 acc: 587.80000
[epoch: 4, batch:    421] loss: 0.00773 time model: 13.85783 acc: 617.25000
[epoch: 4, batch:    441] loss: 0.00769 time model: 14.51612 acc: 646.95000
[epoch: 4, batch:    461] loss: 0.00769 time model: 15.17511 acc: 676.10000
[epoch: 4, batch:    481] loss: 0.00761 time model: 15.83539 acc: 706.30000
[epoch: 4, batch:    501] loss: 0.00766 time model: 16.49436 acc: 735.20000
[epoch: 4, batch:    521] loss: 0.00769 time model: 17.15371 acc: 764.50000
[epoch: 4, batch:    541] loss: 0.00766 time model: 17.81419 acc: 794.20000
[epoch: 4, batch:    561] loss: 0.00760 time model: 18.47351 acc: 824.15000
[epoch: 4, batch:    581] loss: 0.00754 time model: 19.13179 acc: 854.30000
[epoch: 4, batch:    601] loss: 0.00759 time model: 19.79068 acc: 883.25000
[epoch: 4, batch:    621] loss: 0.00762 time model: 20.44912 acc: 912.25000
[epoch: 4, batch:    641] loss: 0.00761 time model: 21.10875 acc: 941.60000
[epoch: 4, batch:    661] loss: 0.00759 time model: 21.75896 acc: 970.60000
[epoch: 4, batch:     21] loss: 0.01035 time model: 0.21025 acc: 28.55000
[epoch: 4, batch:     41] loss: 0.01068 time model: 0.41756 acc: 57.15000
[epoch: 4, batch:     61] loss: 0.01020 time model: 0.62537 acc: 86.15000
[epoch: 4, batch:     81] loss: 0.01046 time model: 0.83375 acc: 113.90000
epoch:4 train loss: 0.007590723440167577 train acc: 0.9197820421701018 valid loss: 0.01042090183457155 valid acc: 0.8901823826154444
[epoch: 5, batch:     21] loss: 0.00760 time model: 0.66112 acc: 29.60000
[epoch: 5, batch:     41] loss: 0.00712 time model: 1.32164 acc: 59.35000
[epoch: 5, batch:     61] loss: 0.00713 time model: 1.98233 acc: 88.80000
[epoch: 5, batch:     81] loss: 0.00721 time model: 2.64403 acc: 117.90000
[epoch: 5, batch:    101] loss: 0.00687 time model: 3.30517 acc: 148.20000
[epoch: 5, batch:    121] loss: 0.00656 time model: 3.96618 acc: 178.80000
[epoch: 5, batch:    141] loss: 0.00658 time model: 4.62758 acc: 208.80000
[epoch: 5, batch:    161] loss: 0.00671 time model: 5.28790 acc: 238.00000
[epoch: 5, batch:    181] loss: 0.00655 time model: 5.94953 acc: 268.10000
[epoch: 5, batch:    201] loss: 0.00679 time model: 6.61029 acc: 297.25000
[epoch: 5, batch:    221] loss: 0.00685 time model: 7.27086 acc: 326.55000
[epoch: 5, batch:    241] loss: 0.00681 time model: 7.93204 acc: 356.20000
[epoch: 5, batch:    261] loss: 0.00671 time model: 8.59355 acc: 386.05000
[epoch: 5, batch:    281] loss: 0.00650 time model: 9.25455 acc: 416.85000
[epoch: 5, batch:    301] loss: 0.00642 time model: 9.91499 acc: 447.10000
[epoch: 5, batch:    321] loss: 0.00642 time model: 10.57661 acc: 476.85000
[epoch: 5, batch:    341] loss: 0.00639 time model: 11.23806 acc: 506.60000
[epoch: 5, batch:    361] loss: 0.00635 time model: 11.89880 acc: 536.90000
[epoch: 5, batch:    381] loss: 0.00626 time model: 12.55948 acc: 567.30000
[epoch: 5, batch:    401] loss: 0.00624 time model: 13.21986 acc: 597.15000
[epoch: 5, batch:    421] loss: 0.00618 time model: 13.88035 acc: 627.25000
[epoch: 5, batch:    441] loss: 0.00618 time model: 14.54101 acc: 657.05000
[epoch: 5, batch:    461] loss: 0.00620 time model: 15.20070 acc: 686.60000
[epoch: 5, batch:    481] loss: 0.00620 time model: 15.86042 acc: 716.30000
[epoch: 5, batch:    501] loss: 0.00623 time model: 16.51960 acc: 745.75000
[epoch: 5, batch:    521] loss: 0.00627 time model: 17.17878 acc: 775.45000
[epoch: 5, batch:    541] loss: 0.00629 time model: 17.83684 acc: 805.60000
[epoch: 5, batch:    561] loss: 0.00628 time model: 18.49591 acc: 835.60000
[epoch: 5, batch:    581] loss: 0.00636 time model: 19.15471 acc: 864.65000
[epoch: 5, batch:    601] loss: 0.00638 time model: 19.81318 acc: 894.25000
[epoch: 5, batch:    621] loss: 0.00633 time model: 20.47166 acc: 924.60000
[epoch: 5, batch:    641] loss: 0.00633 time model: 21.13043 acc: 954.35000
[epoch: 5, batch:    661] loss: 0.00634 time model: 21.77880 acc: 983.55000
[epoch: 5, batch:     21] loss: 0.01202 time model: 0.21088 acc: 28.35000
[epoch: 5, batch:     41] loss: 0.01212 time model: 0.41948 acc: 56.55000
[epoch: 5, batch:     61] loss: 0.01102 time model: 0.62701 acc: 86.05000
[epoch: 5, batch:     81] loss: 0.01109 time model: 0.83485 acc: 114.35000
epoch:5 train loss: 0.006337097672680717 train acc: 0.9320540156361052 valid loss: 0.011247225811211323 valid acc: 0.8928987194412107
[epoch: 6, batch:     21] loss: 0.00664 time model: 0.65951 acc: 29.80000
[epoch: 6, batch:     41] loss: 0.00615 time model: 1.31764 acc: 59.90000
[epoch: 6, batch:     61] loss: 0.00612 time model: 1.97581 acc: 89.85000
[epoch: 6, batch:     81] loss: 0.00595 time model: 2.63479 acc: 120.15000
[epoch: 6, batch:    101] loss: 0.00604 time model: 3.29341 acc: 149.60000
[epoch: 6, batch:    121] loss: 0.00621 time model: 3.95217 acc: 179.00000
[epoch: 6, batch:    141] loss: 0.00602 time model: 4.61041 acc: 209.25000
[epoch: 6, batch:    161] loss: 0.00619 time model: 5.26850 acc: 238.70000
[epoch: 6, batch:    181] loss: 0.00606 time model: 5.92754 acc: 268.65000
[epoch: 6, batch:    201] loss: 0.00612 time model: 6.58627 acc: 298.15000
[epoch: 6, batch:    221] loss: 0.00611 time model: 7.24579 acc: 328.15000
[epoch: 6, batch:    241] loss: 0.00610 time model: 7.90458 acc: 358.20000
[epoch: 6, batch:    261] loss: 0.00595 time model: 8.56369 acc: 388.85000
[epoch: 6, batch:    281] loss: 0.00593 time model: 9.22216 acc: 418.85000
[epoch: 6, batch:    301] loss: 0.00602 time model: 9.88011 acc: 448.60000
[epoch: 6, batch:    321] loss: 0.00601 time model: 10.53859 acc: 478.35000
[epoch: 6, batch:    341] loss: 0.00602 time model: 11.19703 acc: 508.15000
[epoch: 6, batch:    361] loss: 0.00603 time model: 11.85523 acc: 538.05000
[epoch: 6, batch:    381] loss: 0.00600 time model: 12.51365 acc: 568.10000
[epoch: 6, batch:    401] loss: 0.00593 time model: 13.17229 acc: 598.45000
[epoch: 6, batch:    421] loss: 0.00587 time model: 13.83130 acc: 628.70000
[epoch: 6, batch:    441] loss: 0.00582 time model: 14.49020 acc: 658.90000
[epoch: 6, batch:    461] loss: 0.00581 time model: 15.14788 acc: 688.90000
[epoch: 6, batch:    481] loss: 0.00584 time model: 15.80468 acc: 718.60000
[epoch: 6, batch:    501] loss: 0.00578 time model: 16.46142 acc: 749.10000
[epoch: 6, batch:    521] loss: 0.00577 time model: 17.11846 acc: 779.30000
[epoch: 6, batch:    541] loss: 0.00575 time model: 17.77576 acc: 809.60000
[epoch: 6, batch:    561] loss: 0.00577 time model: 18.43233 acc: 839.15000
[epoch: 6, batch:    581] loss: 0.00576 time model: 19.08882 acc: 869.00000
[epoch: 6, batch:    601] loss: 0.00573 time model: 19.74578 acc: 899.20000
[epoch: 6, batch:    621] loss: 0.00571 time model: 20.40363 acc: 929.60000
[epoch: 6, batch:    641] loss: 0.00569 time model: 21.06027 acc: 960.00000
[epoch: 6, batch:    661] loss: 0.00563 time model: 21.70750 acc: 989.90000
[epoch: 6, batch:     21] loss: 0.00716 time model: 0.21007 acc: 29.50000
[epoch: 6, batch:     41] loss: 0.00732 time model: 0.41774 acc: 59.10000
[epoch: 6, batch:     61] loss: 0.00698 time model: 0.62548 acc: 88.80000
[epoch: 6, batch:     81] loss: 0.00713 time model: 0.83268 acc: 118.40000
epoch:6 train loss: 0.0056347774591908525 train acc: 0.9380715470267709 valid loss: 0.007110394572143088 valid acc: 0.9254947613504074
[epoch: 7, batch:     21] loss: 0.00309 time model: 0.65786 acc: 30.85000
[epoch: 7, batch:     41] loss: 0.00403 time model: 1.31423 acc: 61.10000
[epoch: 7, batch:     61] loss: 0.00402 time model: 1.97188 acc: 91.90000
[epoch: 7, batch:     81] loss: 0.00404 time model: 2.62836 acc: 122.30000
[epoch: 7, batch:    101] loss: 0.00400 time model: 3.28474 acc: 153.00000
[epoch: 7, batch:    121] loss: 0.00416 time model: 3.94171 acc: 183.35000
[epoch: 7, batch:    141] loss: 0.00434 time model: 4.59924 acc: 213.60000
[epoch: 7, batch:    161] loss: 0.00453 time model: 5.25578 acc: 243.40000
[epoch: 7, batch:    181] loss: 0.00460 time model: 5.91109 acc: 273.80000
[epoch: 7, batch:    201] loss: 0.00462 time model: 6.56699 acc: 304.10000
[epoch: 7, batch:    221] loss: 0.00474 time model: 7.22321 acc: 334.50000
[epoch: 7, batch:    241] loss: 0.00482 time model: 7.87994 acc: 364.25000
[epoch: 7, batch:    261] loss: 0.00486 time model: 8.53607 acc: 394.80000
[epoch: 7, batch:    281] loss: 0.00495 time model: 9.19247 acc: 424.65000
[epoch: 7, batch:    301] loss: 0.00511 time model: 9.84883 acc: 454.05000
[epoch: 7, batch:    321] loss: 0.00517 time model: 10.50568 acc: 484.20000
[epoch: 7, batch:    341] loss: 0.00516 time model: 11.16233 acc: 514.15000
[epoch: 7, batch:    361] loss: 0.00512 time model: 11.81878 acc: 544.60000
[epoch: 7, batch:    381] loss: 0.00514 time model: 12.47521 acc: 574.45000
[epoch: 7, batch:    401] loss: 0.00511 time model: 13.13171 acc: 605.00000
[epoch: 7, batch:    421] loss: 0.00517 time model: 13.78884 acc: 635.05000
[epoch: 7, batch:    441] loss: 0.00514 time model: 14.44549 acc: 665.35000
[epoch: 7, batch:    461] loss: 0.00510 time model: 15.10200 acc: 696.10000
[epoch: 7, batch:    481] loss: 0.00508 time model: 15.75883 acc: 726.45000
[epoch: 7, batch:    501] loss: 0.00508 time model: 16.41556 acc: 756.65000
[epoch: 7, batch:    521] loss: 0.00504 time model: 17.07172 acc: 787.40000
[epoch: 7, batch:    541] loss: 0.00502 time model: 17.72759 acc: 818.10000
[epoch: 7, batch:    561] loss: 0.00499 time model: 18.38403 acc: 848.65000
[epoch: 7, batch:    581] loss: 0.00496 time model: 19.04087 acc: 879.20000
[epoch: 7, batch:    601] loss: 0.00497 time model: 19.69752 acc: 909.55000
[epoch: 7, batch:    621] loss: 0.00497 time model: 20.35417 acc: 939.90000
[epoch: 7, batch:    641] loss: 0.00497 time model: 21.01079 acc: 970.25000
[epoch: 7, batch:    661] loss: 0.00496 time model: 21.65948 acc: 1000.10000
[epoch: 7, batch:     21] loss: 0.00772 time model: 0.21030 acc: 29.20000
[epoch: 7, batch:     41] loss: 0.00812 time model: 0.41873 acc: 59.40000
[epoch: 7, batch:     61] loss: 0.00807 time model: 0.62641 acc: 88.75000
[epoch: 7, batch:     81] loss: 0.00859 time model: 0.83391 acc: 117.70000
epoch:7 train loss: 0.00495615275786319 train acc: 0.9477375029613836 valid loss: 0.008556240564591672 valid acc: 0.9200620876988747
[epoch: 8, batch:     21] loss: 0.00366 time model: 0.66067 acc: 30.75000
[epoch: 8, batch:     41] loss: 0.00408 time model: 1.32087 acc: 61.35000
[epoch: 8, batch:     61] loss: 0.00371 time model: 1.97984 acc: 92.25000
[epoch: 8, batch:     81] loss: 0.00409 time model: 2.63970 acc: 122.55000
[epoch: 8, batch:    101] loss: 0.00426 time model: 3.29827 acc: 152.90000
[epoch: 8, batch:    121] loss: 0.00429 time model: 3.95701 acc: 183.00000
[epoch: 8, batch:    141] loss: 0.00428 time model: 4.61586 acc: 213.50000
[epoch: 8, batch:    161] loss: 0.00424 time model: 5.27498 acc: 244.15000
[epoch: 8, batch:    181] loss: 0.00427 time model: 5.93483 acc: 274.60000
[epoch: 8, batch:    201] loss: 0.00428 time model: 6.59370 acc: 305.00000
[epoch: 8, batch:    221] loss: 0.00440 time model: 7.25271 acc: 335.10000
[epoch: 8, batch:    241] loss: 0.00446 time model: 7.91218 acc: 365.20000
[epoch: 8, batch:    261] loss: 0.00454 time model: 8.57218 acc: 395.20000
[epoch: 8, batch:    281] loss: 0.00456 time model: 9.23161 acc: 425.20000
[epoch: 8, batch:    301] loss: 0.00470 time model: 9.89046 acc: 455.15000
[epoch: 8, batch:    321] loss: 0.00474 time model: 10.54850 acc: 485.40000
[epoch: 8, batch:    341] loss: 0.00464 time model: 11.20784 acc: 516.55000
[epoch: 8, batch:    361] loss: 0.00466 time model: 11.86647 acc: 546.75000
[epoch: 8, batch:    381] loss: 0.00462 time model: 12.52558 acc: 577.35000
[epoch: 8, batch:    401] loss: 0.00461 time model: 13.18439 acc: 607.80000
[epoch: 8, batch:    421] loss: 0.00457 time model: 13.84353 acc: 638.60000
[epoch: 8, batch:    441] loss: 0.00454 time model: 14.50309 acc: 669.25000
[epoch: 8, batch:    461] loss: 0.00454 time model: 15.16318 acc: 699.55000
[epoch: 8, batch:    481] loss: 0.00450 time model: 15.82223 acc: 730.65000
[epoch: 8, batch:    501] loss: 0.00451 time model: 16.48144 acc: 761.00000
[epoch: 8, batch:    521] loss: 0.00452 time model: 17.14055 acc: 791.45000
[epoch: 8, batch:    541] loss: 0.00448 time model: 17.79959 acc: 822.40000
[epoch: 8, batch:    561] loss: 0.00447 time model: 18.45858 acc: 853.10000
[epoch: 8, batch:    581] loss: 0.00443 time model: 19.11699 acc: 884.05000
[epoch: 8, batch:    601] loss: 0.00441 time model: 19.77608 acc: 914.65000
[epoch: 8, batch:    621] loss: 0.00440 time model: 20.43546 acc: 945.10000
[epoch: 8, batch:    641] loss: 0.00438 time model: 21.09443 acc: 976.00000
[epoch: 8, batch:    661] loss: 0.00442 time model: 21.74371 acc: 1005.50000
[epoch: 8, batch:     21] loss: 0.00784 time model: 0.21117 acc: 29.70000
[epoch: 8, batch:     41] loss: 0.00900 time model: 0.41961 acc: 58.75000
[epoch: 8, batch:     61] loss: 0.00823 time model: 0.62683 acc: 88.50000
[epoch: 8, batch:     81] loss: 0.00782 time model: 0.83453 acc: 118.70000
epoch:8 train loss: 0.004417993127946689 train acc: 0.9528547737502961 valid loss: 0.007885915823902415 valid acc: 0.9266589057043073
[epoch: 9, batch:     21] loss: 0.00322 time model: 0.65938 acc: 30.75000
[epoch: 9, batch:     41] loss: 0.00348 time model: 1.31880 acc: 61.50000
[epoch: 9, batch:     61] loss: 0.00350 time model: 1.97806 acc: 92.10000
[epoch: 9, batch:     81] loss: 0.00353 time model: 2.63806 acc: 122.90000
[epoch: 9, batch:    101] loss: 0.00344 time model: 3.29722 acc: 153.80000
[epoch: 9, batch:    121] loss: 0.00373 time model: 3.95711 acc: 184.05000
[epoch: 9, batch:    141] loss: 0.00375 time model: 4.61650 acc: 214.75000
[epoch: 9, batch:    161] loss: 0.00390 time model: 5.27632 acc: 245.30000
[epoch: 9, batch:    181] loss: 0.00394 time model: 5.93550 acc: 276.05000
[epoch: 9, batch:    201] loss: 0.00396 time model: 6.59453 acc: 306.40000
[epoch: 9, batch:    221] loss: 0.00387 time model: 7.25419 acc: 337.35000
[epoch: 9, batch:    241] loss: 0.00393 time model: 7.91348 acc: 367.75000
[epoch: 9, batch:    261] loss: 0.00404 time model: 8.57215 acc: 397.75000
[epoch: 9, batch:    281] loss: 0.00401 time model: 9.23188 acc: 428.70000
[epoch: 9, batch:    301] loss: 0.00396 time model: 9.89137 acc: 459.60000
[epoch: 9, batch:    321] loss: 0.00395 time model: 10.55049 acc: 490.20000
[epoch: 9, batch:    341] loss: 0.00398 time model: 11.20981 acc: 520.55000
[epoch: 9, batch:    361] loss: 0.00396 time model: 11.86823 acc: 551.25000
[epoch: 9, batch:    381] loss: 0.00396 time model: 12.52808 acc: 581.90000
[epoch: 9, batch:    401] loss: 0.00395 time model: 13.18694 acc: 612.50000
[epoch: 9, batch:    421] loss: 0.00392 time model: 13.84565 acc: 643.15000
[epoch: 9, batch:    441] loss: 0.00396 time model: 14.50469 acc: 673.45000
[epoch: 9, batch:    461] loss: 0.00396 time model: 15.16273 acc: 704.00000
[epoch: 9, batch:    481] loss: 0.00401 time model: 15.82225 acc: 734.20000
[epoch: 9, batch:    501] loss: 0.00409 time model: 16.48192 acc: 764.15000
[epoch: 9, batch:    521] loss: 0.00409 time model: 17.14046 acc: 794.80000
[epoch: 9, batch:    541] loss: 0.00412 time model: 17.79963 acc: 824.85000
[epoch: 9, batch:    561] loss: 0.00421 time model: 18.45868 acc: 854.65000
[epoch: 9, batch:    581] loss: 0.00419 time model: 19.11733 acc: 885.50000
[epoch: 9, batch:    601] loss: 0.00422 time model: 19.77705 acc: 916.25000
[epoch: 9, batch:    621] loss: 0.00423 time model: 20.43608 acc: 946.60000
[epoch: 9, batch:    641] loss: 0.00420 time model: 21.09568 acc: 977.25000
[epoch: 9, batch:    661] loss: 0.00418 time model: 21.74436 acc: 1007.45000
[epoch: 9, batch:     21] loss: 0.00666 time model: 0.21153 acc: 29.85000
[epoch: 9, batch:     41] loss: 0.00773 time model: 0.41935 acc: 59.55000
[epoch: 9, batch:     61] loss: 0.00731 time model: 0.62740 acc: 89.85000
[epoch: 9, batch:     81] loss: 0.00754 time model: 0.83491 acc: 119.15000
epoch:9 train loss: 0.0041838061314246515 train acc: 0.9547026770907368 valid loss: 0.007492905673467933 valid acc: 0.9313154831199069
[epoch: 10, batch:     21] loss: 0.00413 time model: 0.65987 acc: 30.85000
[epoch: 10, batch:     41] loss: 0.00394 time model: 1.31951 acc: 61.50000
[epoch: 10, batch:     61] loss: 0.00366 time model: 1.97970 acc: 92.45000
[epoch: 10, batch:     81] loss: 0.00363 time model: 2.63869 acc: 123.15000
[epoch: 10, batch:    101] loss: 0.00363 time model: 3.29848 acc: 153.85000
[epoch: 10, batch:    121] loss: 0.00359 time model: 3.95810 acc: 184.65000
[epoch: 10, batch:    141] loss: 0.00360 time model: 4.61757 acc: 215.35000
[epoch: 10, batch:    161] loss: 0.00344 time model: 5.27687 acc: 246.75000
[epoch: 10, batch:    181] loss: 0.00345 time model: 5.93662 acc: 277.60000
[epoch: 10, batch:    201] loss: 0.00342 time model: 6.59697 acc: 308.55000
[epoch: 10, batch:    221] loss: 0.00343 time model: 7.25760 acc: 339.30000
[epoch: 10, batch:    241] loss: 0.00345 time model: 7.91756 acc: 369.95000
[epoch: 10, batch:    261] loss: 0.00357 time model: 8.57774 acc: 400.55000
[epoch: 10, batch:    281] loss: 0.00364 time model: 9.23700 acc: 431.10000
[epoch: 10, batch:    301] loss: 0.00373 time model: 9.89665 acc: 461.40000
[epoch: 10, batch:    321] loss: 0.00380 time model: 10.55607 acc: 491.75000
[epoch: 10, batch:    341] loss: 0.00380 time model: 11.21581 acc: 522.60000
[epoch: 10, batch:    361] loss: 0.00370 time model: 11.87487 acc: 553.85000
[epoch: 10, batch:    381] loss: 0.00363 time model: 12.53526 acc: 585.10000
[epoch: 10, batch:    401] loss: 0.00367 time model: 13.19513 acc: 615.65000
[epoch: 10, batch:    421] loss: 0.00375 time model: 13.85371 acc: 645.40000
[epoch: 10, batch:    441] loss: 0.00376 time model: 14.51052 acc: 676.10000
[epoch: 10, batch:    461] loss: 0.00376 time model: 15.16731 acc: 706.70000
[epoch: 10, batch:    481] loss: 0.00376 time model: 15.82335 acc: 737.35000
[epoch: 10, batch:    501] loss: 0.00376 time model: 16.47968 acc: 768.15000
[epoch: 10, batch:    521] loss: 0.00375 time model: 17.13610 acc: 798.80000
[epoch: 10, batch:    541] loss: 0.00378 time model: 17.79222 acc: 829.10000
[epoch: 10, batch:    561] loss: 0.00377 time model: 18.44866 acc: 859.75000
[epoch: 10, batch:    581] loss: 0.00374 time model: 19.10496 acc: 890.70000
[epoch: 10, batch:    601] loss: 0.00377 time model: 19.76194 acc: 921.25000
[epoch: 10, batch:    621] loss: 0.00376 time model: 20.41834 acc: 952.05000
[epoch: 10, batch:    641] loss: 0.00380 time model: 21.07546 acc: 982.65000
[epoch: 10, batch:    661] loss: 0.00381 time model: 21.72191 acc: 1012.40000
[epoch: 10, batch:     21] loss: 0.00711 time model: 0.20891 acc: 29.65000
[epoch: 10, batch:     41] loss: 0.00702 time model: 0.41618 acc: 59.40000
[epoch: 10, batch:     61] loss: 0.00708 time model: 0.62338 acc: 89.05000
[epoch: 10, batch:     81] loss: 0.00744 time model: 0.83024 acc: 118.40000
epoch:10 train loss: 0.0038075737109740065 train acc: 0.95939350864724 valid loss: 0.007400020106262276 valid acc: 0.9254947613504074
