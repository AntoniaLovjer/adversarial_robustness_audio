{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4KBXX6szo28"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14LKOMt0y3rX"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from utils import log_textfile, get_mean_std, load_model\n",
    "from basetrainer import BaseTrainer\n",
    "from dataloader import load_data\n",
    "from CustomDatasetMFCC import CustomDatasetMFCC\n",
    "from models.resnet import ResNet, resnet34\n",
    "from attacks import fgsm, pgd_linf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jpi0p5JP0n24"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21105 train and 2577 val samples\n"
     ]
    }
   ],
   "source": [
    "DATADIR = '../Data/'\n",
    "\n",
    "trainset, valset = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_dl = trainset\n",
    "valset_dl = valset\n",
    "\n",
    "train_filepaths = [i[2] for i in trainset_dl]\n",
    "train_labels = [i[0] for i in trainset_dl]\n",
    "valid_filepaths = [i[2] for i in valset_dl]\n",
    "val_labels = [i[0] for i in valset_dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCzvFAM1rW6x"
   },
   "outputs": [],
   "source": [
    "# from utils import get_mean_std\n",
    "# mean, std = get_mean_std(data_train_mean_std)\n",
    "\n",
    "# mean=-18.949993582525614\n",
    "# std=126.35895609118275\n",
    "\n",
    "mean=-3.121299957927269\n",
    "std=50.02533504630946\n",
    "batch_size=16\n",
    "num_workers=32\n",
    "data_train_sub = CustomDataset(train_filepaths, train_labels, mean, std)\n",
    "data_valid_sub = CustomDataset(valid_filepaths, val_labels, mean, std)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_train_sub, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_valid_sub, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    self._shutdown_workers()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    self._shutdown_workers()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "    w.join()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "    self._shutdown_workers()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "    w.join()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    self._shutdown_workers()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "    w.join()\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "AssertionError: can only join a child process\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    w.join()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "AssertionError: can only join a child process\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcd43dde560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 64 1 7, but got 3-dimensional input of size [32, 10, 20] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2c82b04c4d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                       num_iter=None)\n\u001b[0m",
      "\u001b[0;32m~/Code/basetrainer.py\u001b[0m in \u001b[0;36mfit_model_new\u001b[0;34m(self, optimizer, n_epochs, LOGFILE_PATH, model_filename, attack, epsilon, alpha, num_iter)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m           \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGFILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/basetrainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, epoch, loader, LOGFILE_PATH, optimizer, attack, epsilon, alpha, num_iter)\u001b[0m\n\u001b[1;32m     53\u001b[0m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#         print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#         print(y_true)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/models/resnet.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 64 1 7, but got 3-dimensional input of size [32, 10, 20] instead"
     ]
    }
   ],
   "source": [
    "MODELNAME = 'full_dataset_mfcc_normal'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer_pgd = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer_pgd.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=None, \n",
    "                      epsilon=None, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'full_dataset_mfcc_fgsm_.05'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer_pgd = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer_pgd.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.05, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'full_dataset_mfcc_fgsm_.1'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer_pgd = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer_pgd.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.1, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'full_dataset_mfcc_pgd_.05_.02'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer_pgd = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer_pgd.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=pgd_linf, \n",
    "                      epsilon=0.05, \n",
    "                      alpha=0.01, \n",
    "                      num_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'full_dataset_mfcc_pgd_.1_.05'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer_pgd = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer_pgd.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=pgd_linf, \n",
    "                      epsilon=0.1, \n",
    "                      alpha=0.02, \n",
    "                      num_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'full_dataset_mfcc_normal',\n",
    "    'full_dataset_mfcc_fgsm_.05',\n",
    "    'full_dataset_mfcc_fgsm_.1',\n",
    "    'full_dataset_mfcc_pgd_.05_.02',\n",
    "    'full_dataset_mfcc_pgd_.1_.05'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_params = {\n",
    "    'none': (None, None, None, None),\n",
    "    'fgsm_.05': (fgsm, 0.05, None, None),\n",
    "    'fgsm_.1': (fgsm, 0.1, None, None),\n",
    "    'pgd_.05_.01': (pgd_linf, 0.05, 0.01, 20),\n",
    "    'pgd_.1_.02': (pgd_linf, 0.1, 0.02, 20),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model = torch.load('saved/' + str(model_name))\n",
    "    model = model.eval()\n",
    "    LOGFILE_PATH = model_name + '_eval'\n",
    "    trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=model_name, \n",
    "                      n_epochs=3)\n",
    "    model_results = {}\n",
    "    for param_key in attack_params.keys():\n",
    "        params = attack_params[param_key]\n",
    "        attack = params[0]\n",
    "        epsilon = params[1]\n",
    "        alpha = params[2]\n",
    "        num_iter = params[3]\n",
    "        \n",
    "        loss, acc = trainer.run_epoch(0, valid_data_loader, LOGFILE_PATH, optimizer=None, attack=attack, \n",
    "                          epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "        \n",
    "        if attack!=fgsm:\n",
    "            model_results['pgd' + '_eps_' + str(epsilon) + '_alpha_' + str(alpha) + '_num_iter_' + str(num_iter)] = acc\n",
    "        else:\n",
    "            model_results['fgsm' + '_eps_' + str(epsilon)] = acc\n",
    "        \n",
    "        print(acc)\n",
    "    \n",
    "    print(model_results)\n",
    "\n",
    "            \n",
    "    results[model_name] = model_results\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df.to_csv('results_audio_training_mfcc_10_epochs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "audio_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
