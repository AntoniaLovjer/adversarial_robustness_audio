{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4KBXX6szo28"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14LKOMt0y3rX"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import log_textfile, get_mean_std, windows, pad_dimesions_mfcc, load_model\n",
    "from basetrainer import BaseTrainer\n",
    "from dataloader import load_data\n",
    "from CustomDatasetMFCC import CustomDatasetMFCC\n",
    "from models.resnet import ResNet, resnet34\n",
    "from attacks import fgsm, pgd_linf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jpi0p5JP0n24"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = '../../Data/'\n",
    "\n",
    "data = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('filenames/trainset_10_uids.csv')\n",
    "valset = pd.read_csv('filenames/valset_10_uids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = trainset.drop('Unnamed: 0', axis=1)\n",
    "valset = valset.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "roDTcA97jzUK"
   },
   "source": [
    "### Get filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_dl = [tuple(x) for x in trainset.values]\n",
    "valset_dl = [tuple(x) for x in valset.values]\n",
    "\n",
    "train_filepaths = [i[2] for i in trainset_dl]\n",
    "train_labels = [i[3] for i in trainset_dl]\n",
    "valid_filepaths = [i[2] for i in valset_dl]\n",
    "val_labels = [i[3] for i in valset_dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get mean and standard deviation\n",
    "\n",
    "# x_mean = 0.\n",
    "# x_std = 0.\n",
    "# counter = 0.\n",
    "# for batch in train_data_loader:\n",
    "#     x_mean += np.mean(batch[0].detach().cpu().numpy())\n",
    "#     x_std += np.std(batch[0].detach().cpu().numpy())\n",
    "#     counter += 1\n",
    "# x_mean = x_mean / counter\n",
    "# x_std = x_std / counter\n",
    "# print('mean:', x_mean)\n",
    "# print('std:', x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCzvFAM1rW6x"
   },
   "outputs": [],
   "source": [
    "# from utils import get_mean_std\n",
    "\n",
    "mean=-3.121299957927269\n",
    "std=50.02533504630946\n",
    "batch_size=16\n",
    "num_workers=8\n",
    "data_train_sub = CustomDataset(train_filepaths, train_labels, mean, std)\n",
    "data_valid_sub = CustomDataset(valid_filepaths, val_labels, mean, std)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_train_sub, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_valid_sub, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.14709 time model: 0.02211 acc: 0.20312\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.12642 time model: 0.02191 acc: 0.29688\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.11598 time model: 0.02206 acc: 0.33646\n",
      "epoch:1 train loss: 0.10938134523713665 train acc: 0.3614649681528662 valid loss: 0.15449289878209432 valid acc: 0.38\n",
      "epoch:1 train loss: 0.10938134523713665 train acc: 0.3614649681528662 valid loss: 0.15449289878209432 valid acc: 0.38\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.07598 time model: 0.02203 acc: 0.51562\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.07021 time model: 0.02214 acc: 0.54844\n",
      "60\n",
      "[epoch: 2, batch:     60] loss: 0.06508 time model: 0.02224 acc: 0.58125\n",
      "epoch:2 train loss: 0.06270324842185732 train acc: 0.6098726114649682 valid loss: 0.29199783166249593 valid acc: 0.36666666666666664\n",
      "epoch:2 train loss: 0.06270324842185732 train acc: 0.6098726114649682 valid loss: 0.29199783166249593 valid acc: 0.36666666666666664\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.05053 time model: 0.02229 acc: 0.68125\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.04666 time model: 0.02226 acc: 0.71875\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.04503 time model: 0.02224 acc: 0.74167\n",
      "epoch:3 train loss: 0.04487398848127408 train acc: 0.7492038216560509 valid loss: 0.06884276310602824 valid acc: 0.6133333333333333\n",
      "epoch:3 train loss: 0.04487398848127408 train acc: 0.7492038216560509 valid loss: 0.06884276310602824 valid acc: 0.6133333333333333\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.02584 time model: 0.02237 acc: 0.84688\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.02750 time model: 0.02205 acc: 0.84375\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.02670 time model: 0.02206 acc: 0.85417\n",
      "epoch:4 train loss: 0.025266816258240656 train acc: 0.8670382165605095 valid loss: 0.03747531890869141 valid acc: 0.7933333333333333\n",
      "epoch:4 train loss: 0.025266816258240656 train acc: 0.8670382165605095 valid loss: 0.03747531890869141 valid acc: 0.7933333333333333\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.01866 time model: 0.02210 acc: 0.89375\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.01569 time model: 0.02206 acc: 0.90625\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.01577 time model: 0.02211 acc: 0.90729\n",
      "epoch:5 train loss: 0.01699116251840713 train acc: 0.9020700636942676 valid loss: 0.032954604625701905 valid acc: 0.8666666666666667\n",
      "epoch:5 train loss: 0.01699116251840713 train acc: 0.9020700636942676 valid loss: 0.032954604625701905 valid acc: 0.8666666666666667\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.02239 time model: 0.02228 acc: 0.87813\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.01532 time model: 0.02231 acc: 0.92031\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.01242 time model: 0.02228 acc: 0.93750\n",
      "epoch:6 train loss: 0.011757319449049652 train acc: 0.9394904458598726 valid loss: 0.06438750326633454 valid acc: 0.6866666666666666\n",
      "epoch:6 train loss: 0.011757319449049652 train acc: 0.9394904458598726 valid loss: 0.06438750326633454 valid acc: 0.6866666666666666\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.00763 time model: 0.02238 acc: 0.95625\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.00945 time model: 0.02216 acc: 0.95469\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.00810 time model: 0.02209 acc: 0.95937\n",
      "epoch:7 train loss: 0.008680032779741439 train acc: 0.9554140127388535 valid loss: 0.05007161378860474 valid acc: 0.76\n",
      "epoch:7 train loss: 0.008680032779741439 train acc: 0.9554140127388535 valid loss: 0.05007161378860474 valid acc: 0.76\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.01114 time model: 0.02221 acc: 0.93750\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.01051 time model: 0.02212 acc: 0.94844\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.01091 time model: 0.02202 acc: 0.95000\n",
      "epoch:8 train loss: 0.011362407878515828 train acc: 0.946656050955414 valid loss: 0.10710177679856618 valid acc: 0.7133333333333334\n",
      "epoch:8 train loss: 0.011362407878515828 train acc: 0.946656050955414 valid loss: 0.10710177679856618 valid acc: 0.7133333333333334\n",
      "20\n",
      "[epoch: 9, batch:     20] loss: 0.00699 time model: 0.02221 acc: 0.97813\n",
      "40\n",
      "[epoch: 9, batch:     40] loss: 0.00848 time model: 0.02222 acc: 0.96719\n",
      "60\n",
      "[epoch: 9, batch:     60] loss: 0.00779 time model: 0.02222 acc: 0.96771\n",
      "epoch:9 train loss: 0.007634348550419899 train acc: 0.9673566878980892 valid loss: 0.018195261433720588 valid acc: 0.9333333333333333\n",
      "epoch:9 train loss: 0.007634348550419899 train acc: 0.9673566878980892 valid loss: 0.018195261433720588 valid acc: 0.9333333333333333\n",
      "20\n",
      "[epoch: 10, batch:     20] loss: 0.00607 time model: 0.02244 acc: 0.96875\n",
      "40\n",
      "[epoch: 10, batch:     40] loss: 0.00504 time model: 0.02221 acc: 0.96719\n",
      "60\n",
      "[epoch: 10, batch:     60] loss: 0.00540 time model: 0.02228 acc: 0.96250\n",
      "epoch:10 train loss: 0.0054558690898357685 train acc: 0.9665605095541401 valid loss: 0.016162389318148295 valid acc: 0.92\n",
      "epoch:10 train loss: 0.0054558690898357685 train acc: 0.9665605095541401 valid loss: 0.016162389318148295 valid acc: 0.92\n",
      "Lowest validation loss: 0.016162389318148295, Epoch num: 9\n",
      "Highest accuracy loss: 0.9333333333333333, Epoch num: 8\n"
     ]
    }
   ],
   "source": [
    "MODELNAME = '10_uids_mfcc_resnet_norm_normal_10_epochs_128_redo'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(),lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=None, \n",
    "                      epsilon=None, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.13699 time model: 0.04515 acc: 0.31250\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.11962 time model: 0.04331 acc: 0.32344\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.11483 time model: 0.04275 acc: 0.33021\n",
      "epoch:1 train loss: 0.10738040990890212 train acc: 0.3630573248407643 valid loss: 0.07520805597305298 valid acc: 0.5533333333333333\n",
      "epoch:1 train loss: 0.10738040990890212 train acc: 0.3630573248407643 valid loss: 0.07520805597305298 valid acc: 0.5533333333333333\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.06529 time model: 0.04213 acc: 0.60625\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.06685 time model: 0.04225 acc: 0.58594\n",
      "60\n",
      "[epoch: 2, batch:     60] loss: 0.06750 time model: 0.04236 acc: 0.59375\n",
      "epoch:2 train loss: 0.06708763881473784 train acc: 0.6003184713375797 valid loss: 0.08170975546042124 valid acc: 0.5066666666666667\n",
      "epoch:2 train loss: 0.06708763881473784 train acc: 0.6003184713375797 valid loss: 0.08170975546042124 valid acc: 0.5066666666666667\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.04417 time model: 0.04223 acc: 0.71875\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.04417 time model: 0.04244 acc: 0.71406\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.04535 time model: 0.04244 acc: 0.70937\n",
      "epoch:3 train loss: 0.045136859343879544 train acc: 0.7237261146496815 valid loss: 0.03775192002455394 valid acc: 0.8066666666666666\n",
      "epoch:3 train loss: 0.045136859343879544 train acc: 0.7237261146496815 valid loss: 0.03775192002455394 valid acc: 0.8066666666666666\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.03224 time model: 0.04248 acc: 0.82188\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.03631 time model: 0.04279 acc: 0.79688\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.03798 time model: 0.04284 acc: 0.78958\n",
      "epoch:4 train loss: 0.03495682291923814 train acc: 0.8089171974522293 valid loss: 0.060728347698847454 valid acc: 0.68\n",
      "epoch:4 train loss: 0.03495682291923814 train acc: 0.8089171974522293 valid loss: 0.060728347698847454 valid acc: 0.68\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.02204 time model: 0.04249 acc: 0.86250\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.01960 time model: 0.04264 acc: 0.87969\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.01951 time model: 0.04258 acc: 0.87813\n",
      "epoch:5 train loss: 0.02240751667102431 train acc: 0.8694267515923567 valid loss: 0.05133031944433848 valid acc: 0.7066666666666667\n",
      "epoch:5 train loss: 0.02240751667102431 train acc: 0.8694267515923567 valid loss: 0.05133031944433848 valid acc: 0.7066666666666667\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.02146 time model: 0.04272 acc: 0.89062\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.01959 time model: 0.04285 acc: 0.90312\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.01674 time model: 0.04270 acc: 0.91563\n",
      "epoch:6 train loss: 0.01718345142094193 train acc: 0.9092356687898089 valid loss: 0.04720114673177401 valid acc: 0.7466666666666667\n",
      "epoch:6 train loss: 0.01718345142094193 train acc: 0.9092356687898089 valid loss: 0.04720114673177401 valid acc: 0.7466666666666667\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.02199 time model: 0.04225 acc: 0.88125\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.02618 time model: 0.04250 acc: 0.86094\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.02216 time model: 0.04238 acc: 0.88542\n",
      "epoch:7 train loss: 0.02051795760442497 train acc: 0.8941082802547771 valid loss: 0.01026779110232989 valid acc: 0.94\n",
      "epoch:7 train loss: 0.02051795760442497 train acc: 0.8941082802547771 valid loss: 0.01026779110232989 valid acc: 0.94\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.01915 time model: 0.04237 acc: 0.89062\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.01237 time model: 0.04246 acc: 0.92812\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.01211 time model: 0.04240 acc: 0.93333\n",
      "epoch:8 train loss: 0.012133641441346734 train acc: 0.9371019108280255 valid loss: 0.013841145634651185 valid acc: 0.9466666666666667\n",
      "epoch:8 train loss: 0.012133641441346734 train acc: 0.9371019108280255 valid loss: 0.013841145634651185 valid acc: 0.9466666666666667\n",
      "20\n",
      "[epoch: 9, batch:     20] loss: 0.00788 time model: 0.04268 acc: 0.95937\n",
      "40\n",
      "[epoch: 9, batch:     40] loss: 0.00840 time model: 0.04260 acc: 0.95312\n",
      "60\n",
      "[epoch: 9, batch:     60] loss: 0.00925 time model: 0.04257 acc: 0.94375\n",
      "epoch:9 train loss: 0.008980867921546766 train acc: 0.9482484076433121 valid loss: 0.006856109828998645 valid acc: 0.9733333333333334\n",
      "epoch:9 train loss: 0.008980867921546766 train acc: 0.9482484076433121 valid loss: 0.006856109828998645 valid acc: 0.9733333333333334\n",
      "20\n",
      "[epoch: 10, batch:     20] loss: 0.00895 time model: 0.04284 acc: 0.95312\n",
      "40\n",
      "[epoch: 10, batch:     40] loss: 0.00658 time model: 0.04256 acc: 0.96875\n",
      "60\n",
      "[epoch: 10, batch:     60] loss: 0.00795 time model: 0.04245 acc: 0.96042\n",
      "epoch:10 train loss: 0.008829335996489615 train acc: 0.9546178343949044 valid loss: 0.01689745539178451 valid acc: 0.9066666666666666\n",
      "epoch:10 train loss: 0.008829335996489615 train acc: 0.9546178343949044 valid loss: 0.01689745539178451 valid acc: 0.9066666666666666\n",
      "Lowest validation loss: 0.006856109828998645, Epoch num: 8\n",
      "Highest accuracy loss: 0.9733333333333334, Epoch num: 8\n"
     ]
    }
   ],
   "source": [
    "# FGSM epsilon = 0.05\n",
    "MODELNAME = '10_uids_mfcc_resnet_norm_fgsm_0.05_10_epochs_128'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(),lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.05, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-40f68b02f491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                       num_iter=None)\n\u001b[0m",
      "\u001b[0;32m~/Code/Speaker Verification/basetrainer.py\u001b[0m in \u001b[0;36mfit_model_new\u001b[0;34m(self, optimizer, n_epochs, LOGFILE_PATH, model_filename, attack, epsilon, alpha, num_iter)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m           \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGFILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Speaker Verification/basetrainer.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, epoch, loader, LOGFILE_PATH, optimizer, attack, epsilon, alpha, num_iter)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input criterion is negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FGSM epsilon = 0.1\n",
    "MODELNAME = '10_uids_mfcc_resnet_norm_fgsm_0.1_10_epochs_128'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(),lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.1, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD epsilon = 0.05, alpha = 0.01\n",
    "MODELNAME = '10_uids_mfcc_resnet_norm_pgd_0.5_0.01_10_epochs_128'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(),lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=pgd_linf, \n",
    "                      epsilon=0.05, \n",
    "                      alpha=0.01, \n",
    "                      num_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD epsilon = 0.1, alpha = 0.02\n",
    "MODELNAME = '10_uids_mfcc_resnet_norm_pgd_0.1_0.02_10_epochs_128'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "\n",
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(),lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=pgd_linf, \n",
    "                      epsilon=0.1, \n",
    "                      alpha=0.02, \n",
    "                      num_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [  \n",
    "    '10_uids_mfcc_resnet_norm_normal_10_epochs_128_redo',\n",
    "    '10_uids_mfcc_resnet_norm_fgsm_0.05_10_epochs_128',\n",
    "    '10_uids_mfcc_resnet_norm_fgsm_0.1_10_epochs_128',\n",
    "    '10_uids_mfcc_resnet_norm_pgd_0.05_0.01_10_epochs_128',\n",
    "    '10_uids_mfcc_resnet_norm_pgd_0.1_0.02_10_epochs_128'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_uids_mfcc_resnet_norm_normal_10_epochs_128_redo\n",
      "10_uids_mfcc_resnet_norm_fgsm_0.05_10_epochs_128\n",
      "10_uids_mfcc_resnet_norm_fgsm_0.1_10_epochs_128\n",
      "10_uids_mfcc_resnet_norm_pgd_0.05_0.01_10_epochs_128\n",
      "10_uids_mfcc_resnet_norm_pgd_0.1_0.02_10_epochs_128\n"
     ]
    }
   ],
   "source": [
    "attack_params = {\n",
    "    'none': (None, None, None, None),\n",
    "    'fgsm_.05': (fgsm, 0.05, None, None),\n",
    "    'fgsm_.1': (fgsm, 0.1, None, None),\n",
    "    'pgd_.05_.01': (pgd_linf, 0.05, 0.01, 10),\n",
    "    'pgd_.01_.02': (pgd_linf, 0.1, 0.02, 10)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = resnet34(pretrained=False, progress=False).cuda()\n",
    "    model.load_state_dict(torch.load('saved/' + str(model_name)))\n",
    "    LOGFILE_PATH = model_name + '_eval'\n",
    "    trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=model_name, \n",
    "                      n_epochs=3)\n",
    "    model_results = {}\n",
    "    for param_key in attack_params.keys():\n",
    "        params = attack_params[param_key]\n",
    "        attack = params[0]\n",
    "        epsilon = params[1]\n",
    "        alpha = params[2]\n",
    "        num_iter = params[3]\n",
    "        \n",
    "        loss, acc = trainer.run_epoch(0, valid_data_loader, LOGFILE_PATH, optimizer=None, attack=attack, \n",
    "                          epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "        \n",
    "        if attack!=fgsm:\n",
    "            model_results[param_key] = acc\n",
    "        else:\n",
    "            model_results[param_key] = acc\n",
    "\n",
    "            \n",
    "    results[model_name] = model_results\n",
    "    \n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('results_sv_mfcc_cnn.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "audio_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
