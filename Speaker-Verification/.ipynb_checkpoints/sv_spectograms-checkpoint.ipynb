{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import log_textfile,load_model\n",
    "from basetrainer import BaseTrainer\n",
    "from dataloader import load_data\n",
    "from CustomDataset import CustomDatasetSimple\n",
    "from models.resnet import resnet34\n",
    "from attacks import fgsm, pgd_linf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and prepare train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../../Data/'\n",
    "data = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('filesnames/trainset_10_uids.csv')\n",
    "valset = pd.read_csv('filesnames/valset_10_uids.csv')\n",
    "\n",
    "trainset = trainset.drop('Unnamed: 0', axis=1)\n",
    "valset = valset.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_dl = [tuple(x) for x in trainset.values]\n",
    "valset_dl = [tuple(x) for x in valset.values]\n",
    "\n",
    "train_filepaths = [i[2] for i in trainset_dl]\n",
    "train_labels = [i[3] for i in trainset_dl]\n",
    "valid_filepaths = [i[2] for i in valset_dl]\n",
    "val_labels = [i[3] for i in valset_dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import get_mean_std\n",
    "#mean, std = get_mean_std(train_data_loader)\n",
    "\n",
    "mean=-3.1259581955996425\n",
    "std=0.8961027914827521\n",
    "batch_size=16\n",
    "num_workers=8\n",
    "data_train_sub = CustomDatasetSimple(train_filepaths, train_labels, mean, std)\n",
    "data_valid_sub = CustomDatasetSimple(valid_filepaths, val_labels, mean, std)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_train_sub, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_valid_sub, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_normal_10_epochs_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.11023 time model: 0.02542 acc: 0.12031\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.10049 time model: 0.02540 acc: 0.16250\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.09386 time model: 0.02540 acc: 0.18594\n",
      "80\n",
      "[epoch: 1, batch:     80] loss: 0.09003 time model: 0.02539 acc: 0.20898\n",
      "100\n",
      "[epoch: 1, batch:    100] loss: 0.08579 time model: 0.02537 acc: 0.23906\n",
      "epoch:1 train loss: 0.08470685479970404 train acc: 0.2447572536627406 valid loss: 0.1669788106282552 valid acc: 0.16\n",
      "epoch:1 train loss: 0.08470685479970404 train acc: 0.2447572536627406 valid loss: 0.1669788106282552 valid acc: 0.16\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.06293 time model: 0.02542 acc: 0.37969\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.06018 time model: 0.02540 acc: 0.42266\n",
      "60\n",
      "[epoch: 2, batch:     60] loss: 0.05780 time model: 0.02540 acc: 0.45104\n",
      "80\n",
      "[epoch: 2, batch:     80] loss: 0.05560 time model: 0.02539 acc: 0.46172\n",
      "100\n",
      "[epoch: 2, batch:    100] loss: 0.05310 time model: 0.02539 acc: 0.48812\n",
      "epoch:2 train loss: 0.0522734347310295 train acc: 0.4972708991669061 valid loss: 0.07833436965942382 valid acc: 0.3333333333333333\n",
      "epoch:2 train loss: 0.0522734347310295 train acc: 0.4972708991669061 valid loss: 0.07833436965942382 valid acc: 0.3333333333333333\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.03597 time model: 0.02542 acc: 0.67031\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.03552 time model: 0.02541 acc: 0.67422\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.03495 time model: 0.02540 acc: 0.66927\n",
      "80\n",
      "[epoch: 3, batch:     80] loss: 0.03333 time model: 0.02540 acc: 0.68555\n",
      "100\n",
      "[epoch: 3, batch:    100] loss: 0.03270 time model: 0.02539 acc: 0.68969\n",
      "epoch:3 train loss: 0.03229496709165543 train acc: 0.693478885377765 valid loss: 0.11434309164683024 valid acc: 0.32\n",
      "epoch:3 train loss: 0.03229496709165543 train acc: 0.693478885377765 valid loss: 0.11434309164683024 valid acc: 0.32\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.02350 time model: 0.02538 acc: 0.77969\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.02364 time model: 0.02537 acc: 0.77891\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.02297 time model: 0.02538 acc: 0.78542\n",
      "80\n",
      "[epoch: 4, batch:     80] loss: 0.02273 time model: 0.02537 acc: 0.79180\n",
      "100\n",
      "[epoch: 4, batch:    100] loss: 0.02169 time model: 0.02537 acc: 0.80031\n",
      "epoch:4 train loss: 0.021348053809384853 train acc: 0.8052283826486641 valid loss: 0.14240981260935465 valid acc: 0.24666666666666667\n",
      "epoch:4 train loss: 0.021348053809384853 train acc: 0.8052283826486641 valid loss: 0.14240981260935465 valid acc: 0.24666666666666667\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.01510 time model: 0.02546 acc: 0.86250\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.01535 time model: 0.02544 acc: 0.85313\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.01524 time model: 0.02542 acc: 0.85729\n",
      "80\n",
      "[epoch: 5, batch:     80] loss: 0.01484 time model: 0.02542 acc: 0.86445\n",
      "100\n",
      "[epoch: 5, batch:    100] loss: 0.01475 time model: 0.02541 acc: 0.86687\n",
      "epoch:5 train loss: 0.014740238558523478 train acc: 0.866704969836254 valid loss: 0.10200321674346924 valid acc: 0.37333333333333335\n",
      "epoch:5 train loss: 0.014740238558523478 train acc: 0.866704969836254 valid loss: 0.10200321674346924 valid acc: 0.37333333333333335\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.01186 time model: 0.02553 acc: 0.89062\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.01215 time model: 0.02547 acc: 0.88906\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.01165 time model: 0.02544 acc: 0.89219\n",
      "80\n",
      "[epoch: 6, batch:     80] loss: 0.01164 time model: 0.02543 acc: 0.89258\n",
      "100\n",
      "[epoch: 6, batch:    100] loss: 0.01180 time model: 0.02542 acc: 0.89125\n",
      "epoch:6 train loss: 0.011768758070088776 train acc: 0.8902614191324332 valid loss: 0.07610032081604004 valid acc: 0.5333333333333333\n",
      "epoch:6 train loss: 0.011768758070088776 train acc: 0.8902614191324332 valid loss: 0.07610032081604004 valid acc: 0.5333333333333333\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.00858 time model: 0.02541 acc: 0.92812\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.00917 time model: 0.02540 acc: 0.92422\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.00938 time model: 0.02537 acc: 0.91719\n",
      "80\n",
      "[epoch: 7, batch:     80] loss: 0.00929 time model: 0.02535 acc: 0.92070\n",
      "100\n",
      "[epoch: 7, batch:    100] loss: 0.00887 time model: 0.02534 acc: 0.92437\n",
      "epoch:7 train loss: 0.00886489772413079 train acc: 0.9247342717609882 valid loss: 0.025029837489128112 valid acc: 0.78\n",
      "epoch:7 train loss: 0.00886489772413079 train acc: 0.9247342717609882 valid loss: 0.025029837489128112 valid acc: 0.78\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.00788 time model: 0.02543 acc: 0.93594\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.00802 time model: 0.02541 acc: 0.93047\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.00712 time model: 0.02541 acc: 0.93698\n",
      "80\n",
      "[epoch: 8, batch:     80] loss: 0.00699 time model: 0.02541 acc: 0.93867\n",
      "100\n",
      "[epoch: 8, batch:    100] loss: 0.00667 time model: 0.02539 acc: 0.94281\n",
      "epoch:8 train loss: 0.006703140641621768 train acc: 0.9422579718471703 valid loss: 0.015775939524173735 valid acc: 0.8666666666666667\n",
      "epoch:8 train loss: 0.006703140641621768 train acc: 0.9422579718471703 valid loss: 0.015775939524173735 valid acc: 0.8666666666666667\n",
      "20\n",
      "[epoch: 9, batch:     20] loss: 0.00502 time model: 0.02539 acc: 0.96719\n",
      "40\n",
      "[epoch: 9, batch:     40] loss: 0.00476 time model: 0.02537 acc: 0.96172\n",
      "60\n",
      "[epoch: 9, batch:     60] loss: 0.00464 time model: 0.02537 acc: 0.96146\n",
      "80\n",
      "[epoch: 9, batch:     80] loss: 0.00473 time model: 0.02537 acc: 0.96016\n",
      "100\n",
      "[epoch: 9, batch:    100] loss: 0.00482 time model: 0.02537 acc: 0.95906\n",
      "epoch:9 train loss: 0.0048542149885054875 train acc: 0.9594943981614479 valid loss: 0.013354624509811402 valid acc: 0.9\n",
      "epoch:9 train loss: 0.0048542149885054875 train acc: 0.9594943981614479 valid loss: 0.013354624509811402 valid acc: 0.9\n",
      "20\n",
      "[epoch: 10, batch:     20] loss: 0.00434 time model: 0.02542 acc: 0.95625\n",
      "40\n",
      "[epoch: 10, batch:     40] loss: 0.00527 time model: 0.02540 acc: 0.95234\n",
      "60\n",
      "[epoch: 10, batch:     60] loss: 0.00503 time model: 0.02538 acc: 0.95312\n",
      "80\n",
      "[epoch: 10, batch:     80] loss: 0.00491 time model: 0.02536 acc: 0.95391\n",
      "100\n",
      "[epoch: 10, batch:    100] loss: 0.00513 time model: 0.02536 acc: 0.95156\n",
      "epoch:10 train loss: 0.0051208461402853615 train acc: 0.951738006320023 valid loss: 0.011600349346796672 valid acc: 0.9133333333333333\n",
      "epoch:10 train loss: 0.0051208461402853615 train acc: 0.951738006320023 valid loss: 0.011600349346796672 valid acc: 0.9133333333333333\n",
      "Lowest validation loss: 0.011600349346796672, Epoch num: 9\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=None, \n",
    "                      epsilon=None, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_fgsm_.05_10_epochs_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.12101 time model: 0.05034 acc: 0.06875\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.11054 time model: 0.05035 acc: 0.10391\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.10574 time model: 0.05037 acc: 0.11302\n",
      "80\n",
      "[epoch: 1, batch:     80] loss: 0.10148 time model: 0.05037 acc: 0.13437\n",
      "100\n",
      "[epoch: 1, batch:    100] loss: 0.09825 time model: 0.05036 acc: 0.14719\n",
      "epoch:1 train loss: 0.09697509120162004 train acc: 0.15800057454754382 valid loss: 0.17395661354064942 valid acc: 0.16\n",
      "epoch:1 train loss: 0.09697509120162004 train acc: 0.15800057454754382 valid loss: 0.17395661354064942 valid acc: 0.16\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.07569 time model: 0.05036 acc: 0.28906\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.07302 time model: 0.05035 acc: 0.30703\n",
      "60\n",
      "[epoch: 2, batch:     60] loss: 0.07171 time model: 0.05035 acc: 0.31250\n",
      "80\n",
      "[epoch: 2, batch:     80] loss: 0.06912 time model: 0.05034 acc: 0.32461\n",
      "100\n",
      "[epoch: 2, batch:    100] loss: 0.06677 time model: 0.05035 acc: 0.34094\n",
      "epoch:2 train loss: 0.06615059148371477 train acc: 0.3447285262855501 valid loss: 0.05944959004720052 valid acc: 0.48\n",
      "epoch:2 train loss: 0.06615059148371477 train acc: 0.3447285262855501 valid loss: 0.05944959004720052 valid acc: 0.48\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.05524 time model: 0.05037 acc: 0.40469\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.05257 time model: 0.05038 acc: 0.44375\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.05157 time model: 0.05035 acc: 0.46094\n",
      "80\n",
      "[epoch: 3, batch:     80] loss: 0.05068 time model: 0.05035 acc: 0.47305\n",
      "100\n",
      "[epoch: 3, batch:    100] loss: 0.05062 time model: 0.05035 acc: 0.48187\n",
      "epoch:3 train loss: 0.050473733661983655 train acc: 0.4820453892559609 valid loss: 0.09524166107177734 valid acc: 0.3466666666666667\n",
      "epoch:3 train loss: 0.050473733661983655 train acc: 0.4820453892559609 valid loss: 0.09524166107177734 valid acc: 0.3466666666666667\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.04193 time model: 0.05036 acc: 0.58750\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.04170 time model: 0.05036 acc: 0.57656\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.04209 time model: 0.05035 acc: 0.57083\n",
      "80\n",
      "[epoch: 4, batch:     80] loss: 0.04087 time model: 0.05035 acc: 0.57656\n",
      "100\n",
      "[epoch: 4, batch:    100] loss: 0.04097 time model: 0.05035 acc: 0.57625\n",
      "epoch:4 train loss: 0.040917755012298516 train acc: 0.5765584602125826 valid loss: 0.04765828728675842 valid acc: 0.5266666666666666\n",
      "epoch:4 train loss: 0.040917755012298516 train acc: 0.5765584602125826 valid loss: 0.04765828728675842 valid acc: 0.5266666666666666\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.03489 time model: 0.05038 acc: 0.63125\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.03409 time model: 0.05034 acc: 0.64219\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.03321 time model: 0.05029 acc: 0.65104\n",
      "80\n",
      "[epoch: 5, batch:     80] loss: 0.03248 time model: 0.05031 acc: 0.65977\n",
      "100\n",
      "[epoch: 5, batch:    100] loss: 0.03173 time model: 0.05032 acc: 0.66781\n",
      "epoch:5 train loss: 0.031938693006981794 train acc: 0.6664751508187302 valid loss: 0.049823152224222816 valid acc: 0.54\n",
      "epoch:5 train loss: 0.031938693006981794 train acc: 0.6664751508187302 valid loss: 0.049823152224222816 valid acc: 0.54\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.02651 time model: 0.05037 acc: 0.70937\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.02708 time model: 0.05038 acc: 0.70781\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.02708 time model: 0.05039 acc: 0.71354\n",
      "80\n",
      "[epoch: 6, batch:     80] loss: 0.02694 time model: 0.05039 acc: 0.71523\n",
      "100\n",
      "[epoch: 6, batch:    100] loss: 0.02656 time model: 0.05039 acc: 0.72000\n",
      "epoch:6 train loss: 0.026674795907586858 train acc: 0.7190462510772766 valid loss: 0.031680021286010746 valid acc: 0.72\n",
      "epoch:6 train loss: 0.026674795907586858 train acc: 0.7190462510772766 valid loss: 0.031680021286010746 valid acc: 0.72\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.02763 time model: 0.05041 acc: 0.71406\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.02656 time model: 0.05041 acc: 0.71641\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.02553 time model: 0.05041 acc: 0.72813\n",
      "80\n",
      "[epoch: 7, batch:     80] loss: 0.02492 time model: 0.05040 acc: 0.73984\n",
      "100\n",
      "[epoch: 7, batch:    100] loss: 0.02433 time model: 0.05040 acc: 0.74594\n",
      "epoch:7 train loss: 0.024127751075135876 train acc: 0.7492099971272623 valid loss: 0.028401933113733926 valid acc: 0.7333333333333333\n",
      "epoch:7 train loss: 0.024127751075135876 train acc: 0.7492099971272623 valid loss: 0.028401933113733926 valid acc: 0.7333333333333333\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.01798 time model: 0.05042 acc: 0.81250\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.01756 time model: 0.05039 acc: 0.81406\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.01859 time model: 0.05038 acc: 0.81094\n",
      "80\n",
      "[epoch: 8, batch:     80] loss: 0.01836 time model: 0.05038 acc: 0.80781\n",
      "100\n",
      "[epoch: 8, batch:    100] loss: 0.01852 time model: 0.05037 acc: 0.80344\n",
      "epoch:8 train loss: 0.019463788894564557 train acc: 0.7934501580005745 valid loss: 0.03167105754216512 valid acc: 0.7466666666666667\n",
      "epoch:8 train loss: 0.019463788894564557 train acc: 0.7934501580005745 valid loss: 0.03167105754216512 valid acc: 0.7466666666666667\n",
      "20\n",
      "[epoch: 9, batch:     20] loss: 0.01895 time model: 0.05030 acc: 0.80781\n",
      "40\n",
      "[epoch: 9, batch:     40] loss: 0.01794 time model: 0.05029 acc: 0.81875\n",
      "60\n",
      "[epoch: 9, batch:     60] loss: 0.01680 time model: 0.05032 acc: 0.82812\n",
      "80\n",
      "[epoch: 9, batch:     80] loss: 0.01646 time model: 0.05033 acc: 0.83086\n",
      "100\n",
      "[epoch: 9, batch:    100] loss: 0.01624 time model: 0.05027 acc: 0.83000\n",
      "epoch:9 train loss: 0.015999616523715007 train acc: 0.832232117207699 valid loss: 0.02465879837671916 valid acc: 0.7733333333333333\n",
      "epoch:9 train loss: 0.015999616523715007 train acc: 0.832232117207699 valid loss: 0.02465879837671916 valid acc: 0.7733333333333333\n",
      "20\n",
      "[epoch: 10, batch:     20] loss: 0.01316 time model: 0.05023 acc: 0.85938\n",
      "40\n",
      "[epoch: 10, batch:     40] loss: 0.01411 time model: 0.05015 acc: 0.84922\n",
      "60\n",
      "[epoch: 10, batch:     60] loss: 0.01396 time model: 0.05013 acc: 0.84479\n",
      "80\n",
      "[epoch: 10, batch:     80] loss: 0.01370 time model: 0.05012 acc: 0.84883\n",
      "100\n",
      "[epoch: 10, batch:    100] loss: 0.01361 time model: 0.05014 acc: 0.85000\n",
      "epoch:10 train loss: 0.013664853321139547 train acc: 0.8491812697500718 valid loss: 0.021823208729426065 valid acc: 0.8066666666666666\n",
      "epoch:10 train loss: 0.013664853321139547 train acc: 0.8491812697500718 valid loss: 0.021823208729426065 valid acc: 0.8066666666666666\n",
      "Lowest validation loss: 0.021823208729426065, Epoch num: 9\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.05, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_10_epochs_fgsm_0.1_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.11768 time model: 0.05023 acc: 0.07344\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.10713 time model: 0.05022 acc: 0.11094\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.10085 time model: 0.05021 acc: 0.13802\n",
      "80\n",
      "[epoch: 1, batch:     80] loss: 0.09690 time model: 0.05021 acc: 0.15781\n",
      "100\n",
      "[epoch: 1, batch:    100] loss: 0.09309 time model: 0.05022 acc: 0.18125\n",
      "epoch:1 train loss: 0.09172494560094854 train acc: 0.1910370583165757 valid loss: 0.10466446876525878 valid acc: 0.19333333333333333\n",
      "epoch:1 train loss: 0.09172494560094854 train acc: 0.1910370583165757 valid loss: 0.10466446876525878 valid acc: 0.19333333333333333\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.07140 time model: 0.05040 acc: 0.33281\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.06838 time model: 0.05039 acc: 0.33672\n",
      "100\n",
      "[epoch: 2, batch:    100] loss: 0.06023 time model: 0.05042 acc: 0.41219\n",
      "epoch:2 train loss: 0.059670716104614295 train acc: 0.4179833381212295 valid loss: 0.10539337952931722 valid acc: 0.24666666666666667\n",
      "epoch:2 train loss: 0.059670716104614295 train acc: 0.4179833381212295 valid loss: 0.10539337952931722 valid acc: 0.24666666666666667\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.04287 time model: 0.05044 acc: 0.56563\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.04059 time model: 0.05044 acc: 0.59297\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.04111 time model: 0.05044 acc: 0.59010\n",
      "80\n",
      "[epoch: 3, batch:     80] loss: 0.04038 time model: 0.05044 acc: 0.60117\n",
      "100\n",
      "[epoch: 3, batch:    100] loss: 0.03874 time model: 0.05043 acc: 0.61781\n",
      "epoch:3 train loss: 0.038587374544732704 train acc: 0.6228095374892272 valid loss: 0.2173017613093058 valid acc: 0.28\n",
      "epoch:3 train loss: 0.038587374544732704 train acc: 0.6228095374892272 valid loss: 0.2173017613093058 valid acc: 0.28\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.02827 time model: 0.05046 acc: 0.71875\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.02861 time model: 0.05045 acc: 0.72813\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.02875 time model: 0.05045 acc: 0.72917\n",
      "80\n",
      "[epoch: 4, batch:     80] loss: 0.02835 time model: 0.05046 acc: 0.73672\n",
      "100\n",
      "[epoch: 4, batch:    100] loss: 0.02791 time model: 0.05046 acc: 0.73281\n",
      "epoch:4 train loss: 0.02809589578995106 train acc: 0.7282390117782247 valid loss: 0.06370821714401245 valid acc: 0.5466666666666666\n",
      "epoch:4 train loss: 0.02809589578995106 train acc: 0.7282390117782247 valid loss: 0.06370821714401245 valid acc: 0.5466666666666666\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.02392 time model: 0.05055 acc: 0.75938\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.02265 time model: 0.05055 acc: 0.78047\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.02146 time model: 0.05054 acc: 0.79583\n",
      "80\n",
      "[epoch: 5, batch:     80] loss: 0.02126 time model: 0.05054 acc: 0.79727\n",
      "100\n",
      "[epoch: 5, batch:    100] loss: 0.02126 time model: 0.05054 acc: 0.79563\n",
      "epoch:5 train loss: 0.020980433430078556 train acc: 0.7977592645791439 valid loss: 0.030850769678751628 valid acc: 0.74\n",
      "epoch:5 train loss: 0.020980433430078556 train acc: 0.7977592645791439 valid loss: 0.030850769678751628 valid acc: 0.74\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.01632 time model: 0.05055 acc: 0.85313\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.01630 time model: 0.05049 acc: 0.84297\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.01564 time model: 0.05046 acc: 0.84323\n",
      "80\n",
      "[epoch: 6, batch:     80] loss: 0.01539 time model: 0.05042 acc: 0.84492\n",
      "100\n",
      "[epoch: 6, batch:    100] loss: 0.01556 time model: 0.05041 acc: 0.84531\n",
      "epoch:6 train loss: 0.015449998986443648 train acc: 0.8480321746624533 valid loss: 0.019564679662386578 valid acc: 0.8133333333333334\n",
      "epoch:6 train loss: 0.015449998986443648 train acc: 0.8480321746624533 valid loss: 0.019564679662386578 valid acc: 0.8133333333333334\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.01187 time model: 0.05046 acc: 0.87656\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.01210 time model: 0.05048 acc: 0.88047\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.01196 time model: 0.05049 acc: 0.88438\n",
      "80\n",
      "[epoch: 7, batch:     80] loss: 0.01148 time model: 0.05046 acc: 0.88867\n",
      "100\n",
      "[epoch: 7, batch:    100] loss: 0.01129 time model: 0.05043 acc: 0.89250\n",
      "epoch:7 train loss: 0.011224604430331542 train acc: 0.8925596093076702 valid loss: 0.0222574253877004 valid acc: 0.8266666666666667\n",
      "epoch:7 train loss: 0.011224604430331542 train acc: 0.8925596093076702 valid loss: 0.0222574253877004 valid acc: 0.8266666666666667\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.00937 time model: 0.05030 acc: 0.90781\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.00878 time model: 0.05022 acc: 0.91406\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.00991 time model: 0.05020 acc: 0.89792\n",
      "80\n",
      "[epoch: 8, batch:     80] loss: 0.01052 time model: 0.05016 acc: 0.89609\n",
      "100\n",
      "[epoch: 8, batch:    100] loss: 0.01050 time model: 0.05014 acc: 0.89531\n",
      "epoch:8 train loss: 0.010278442983173906 train acc: 0.8985923585176674 valid loss: 0.015221221148967743 valid acc: 0.88\n",
      "epoch:8 train loss: 0.010278442983173906 train acc: 0.8985923585176674 valid loss: 0.015221221148967743 valid acc: 0.88\n",
      "20\n",
      "[epoch: 9, batch:     20] loss: 0.00752 time model: 0.05027 acc: 0.91719\n",
      "40\n",
      "[epoch: 9, batch:     40] loss: 0.00755 time model: 0.05027 acc: 0.92109\n",
      "60\n",
      "[epoch: 9, batch:     60] loss: 0.00727 time model: 0.05027 acc: 0.92917\n",
      "80\n",
      "[epoch: 9, batch:     80] loss: 0.00751 time model: 0.05029 acc: 0.92500\n",
      "100\n",
      "[epoch: 9, batch:    100] loss: 0.00788 time model: 0.05028 acc: 0.92000\n",
      "epoch:9 train loss: 0.007992936176785927 train acc: 0.9192760700948004 valid loss: 0.018290138443311055 valid acc: 0.8733333333333333\n",
      "epoch:9 train loss: 0.007992936176785927 train acc: 0.9192760700948004 valid loss: 0.018290138443311055 valid acc: 0.8733333333333333\n",
      "20\n",
      "[epoch: 10, batch:     20] loss: 0.00628 time model: 0.05023 acc: 0.94063\n",
      "40\n",
      "[epoch: 10, batch:     40] loss: 0.00589 time model: 0.05022 acc: 0.93984\n",
      "60\n",
      "[epoch: 10, batch:     60] loss: 0.00618 time model: 0.05021 acc: 0.93542\n",
      "80\n",
      "[epoch: 10, batch:     80] loss: 0.00624 time model: 0.05021 acc: 0.93516\n",
      "100\n",
      "[epoch: 10, batch:    100] loss: 0.00589 time model: 0.05022 acc: 0.94063\n",
      "epoch:10 train loss: 0.005763952101023503 train acc: 0.9428325193909796 valid loss: 0.011791714628537496 valid acc: 0.9\n",
      "epoch:10 train loss: 0.005763952101023503 train acc: 0.9428325193909796 valid loss: 0.011791714628537496 valid acc: 0.9\n",
      "Lowest validation loss: 0.011791714628537496, Epoch num: 9\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.1, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_10_epochs_fgsm_0.3_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.12218 time model: 0.27509 acc: 0.04844\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.11230 time model: 0.27509 acc: 0.07266\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.10753 time model: 0.27521 acc: 0.08854\n",
      "80\n",
      "[epoch: 1, batch:     80] loss: 0.10415 time model: 0.27524 acc: 0.10938\n",
      "100\n",
      "[epoch: 1, batch:    100] loss: 0.10113 time model: 0.27529 acc: 0.12406\n",
      "epoch:1 train loss: 0.1001495140374854 train acc: 0.1315713875323183 valid loss: 0.10711635907491047 valid acc: 0.12\n",
      "epoch:1 train loss: 0.1001495140374854 train acc: 0.1315713875323183 valid loss: 0.10711635907491047 valid acc: 0.12\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.08300 time model: 0.27537 acc: 0.22656\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.07949 time model: 0.27558 acc: 0.25391\n",
      "60\n",
      "[epoch: 2, batch:     60] loss: 0.07792 time model: 0.27567 acc: 0.26875\n",
      "80\n",
      "[epoch: 2, batch:     80] loss: 0.07658 time model: 0.27571 acc: 0.27734\n",
      "100\n",
      "[epoch: 2, batch:    100] loss: 0.07444 time model: 0.27571 acc: 0.29219\n",
      "epoch:2 train loss: 0.07324115940977259 train acc: 0.301924734271761 valid loss: 0.06386271556218465 valid acc: 0.44666666666666666\n",
      "epoch:2 train loss: 0.07324115940977259 train acc: 0.301924734271761 valid loss: 0.06386271556218465 valid acc: 0.44666666666666666\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.05785 time model: 0.27531 acc: 0.42500\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.05772 time model: 0.27533 acc: 0.40937\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.05667 time model: 0.27530 acc: 0.41719\n",
      "80\n",
      "[epoch: 3, batch:     80] loss: 0.05505 time model: 0.27529 acc: 0.43438\n",
      "100\n",
      "[epoch: 3, batch:    100] loss: 0.05445 time model: 0.27528 acc: 0.43844\n",
      "epoch:3 train loss: 0.05428691363752453 train acc: 0.4415397874174088 valid loss: 0.05376010497411092 valid acc: 0.47333333333333333\n",
      "epoch:3 train loss: 0.05428691363752453 train acc: 0.4415397874174088 valid loss: 0.05376010497411092 valid acc: 0.47333333333333333\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.04569 time model: 0.27521 acc: 0.52031\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.04612 time model: 0.27537 acc: 0.52109\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.04602 time model: 0.27546 acc: 0.52396\n",
      "80\n",
      "[epoch: 4, batch:     80] loss: 0.04538 time model: 0.27551 acc: 0.53281\n",
      "100\n",
      "[epoch: 4, batch:    100] loss: 0.04489 time model: 0.27556 acc: 0.53312\n",
      "epoch:4 train loss: 0.04444902520589327 train acc: 0.537201953461649 valid loss: 0.0387758473555247 valid acc: 0.7\n",
      "epoch:4 train loss: 0.04444902520589327 train acc: 0.537201953461649 valid loss: 0.0387758473555247 valid acc: 0.7\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.03691 time model: 0.27558 acc: 0.61719\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.03664 time model: 0.27554 acc: 0.62969\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.03633 time model: 0.27549 acc: 0.62917\n",
      "80\n",
      "[epoch: 5, batch:     80] loss: 0.03614 time model: 0.27541 acc: 0.62461\n",
      "100\n",
      "[epoch: 5, batch:    100] loss: 0.03547 time model: 0.27538 acc: 0.62656\n",
      "epoch:5 train loss: 0.035031200431263745 train acc: 0.6331513932777937 valid loss: 0.04095253705978394 valid acc: 0.68\n",
      "epoch:5 train loss: 0.035031200431263745 train acc: 0.6331513932777937 valid loss: 0.04095253705978394 valid acc: 0.68\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.02987 time model: 0.27476 acc: 0.70469\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.02943 time model: 0.27487 acc: 0.70547\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.02880 time model: 0.27521 acc: 0.70833\n",
      "80\n",
      "[epoch: 6, batch:     80] loss: 0.02896 time model: 0.27540 acc: 0.70586\n",
      "100\n",
      "[epoch: 6, batch:    100] loss: 0.02902 time model: 0.27556 acc: 0.70437\n",
      "epoch:6 train loss: 0.029367619275156364 train acc: 0.7012352772191899 valid loss: 0.031287391185760495 valid acc: 0.74\n",
      "epoch:6 train loss: 0.029367619275156364 train acc: 0.7012352772191899 valid loss: 0.031287391185760495 valid acc: 0.74\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.02506 time model: 0.27560 acc: 0.72344\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.02469 time model: 0.27560 acc: 0.72344\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.02378 time model: 0.27548 acc: 0.74167\n",
      "80\n",
      "[epoch: 7, batch:     80] loss: 0.02435 time model: 0.27538 acc: 0.73359\n",
      "100\n",
      "[epoch: 7, batch:    100] loss: 0.02441 time model: 0.27530 acc: 0.73750\n",
      "epoch:7 train loss: 0.024402060657011917 train acc: 0.7380063200229819 valid loss: 0.024436907768249513 valid acc: 0.7866666666666666\n",
      "epoch:7 train loss: 0.024402060657011917 train acc: 0.7380063200229819 valid loss: 0.024436907768249513 valid acc: 0.7866666666666666\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.02292 time model: 0.27540 acc: 0.75938\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.02183 time model: 0.27530 acc: 0.77031\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.02099 time model: 0.27537 acc: 0.77396\n",
      "80\n",
      "[epoch: 8, batch:     80] loss: 0.02104 time model: 0.27542 acc: 0.77422\n",
      "100\n",
      "[epoch: 8, batch:    100] loss: 0.02057 time model: 0.27544 acc: 0.77687\n",
      "epoch:8 train loss: 0.02035415395173969 train acc: 0.7825337546681987 valid loss: 0.02604819138844808 valid acc: 0.8066666666666666\n",
      "epoch:8 train loss: 0.02035415395173969 train acc: 0.7825337546681987 valid loss: 0.02604819138844808 valid acc: 0.8066666666666666\n",
      "20\n",
      "[epoch: 9, batch:     20] loss: 0.02069 time model: 0.27535 acc: 0.75781\n",
      "40\n",
      "[epoch: 9, batch:     40] loss: 0.01862 time model: 0.27534 acc: 0.78516\n",
      "60\n",
      "[epoch: 9, batch:     60] loss: 0.01767 time model: 0.27535 acc: 0.79323\n",
      "80\n",
      "[epoch: 9, batch:     80] loss: 0.01739 time model: 0.27536 acc: 0.80039\n",
      "100\n",
      "[epoch: 9, batch:    100] loss: 0.01772 time model: 0.27534 acc: 0.79750\n",
      "epoch:9 train loss: 0.01782687106837284 train acc: 0.7954610744039069 valid loss: 0.02432593802611033 valid acc: 0.8\n",
      "epoch:9 train loss: 0.01782687106837284 train acc: 0.7954610744039069 valid loss: 0.02432593802611033 valid acc: 0.8\n",
      "20\n",
      "[epoch: 10, batch:     20] loss: 0.01854 time model: 0.27595 acc: 0.79375\n",
      "40\n",
      "[epoch: 10, batch:     40] loss: 0.01664 time model: 0.27594 acc: 0.82344\n",
      "60\n",
      "[epoch: 10, batch:     60] loss: 0.01668 time model: 0.27596 acc: 0.82240\n",
      "80\n",
      "[epoch: 10, batch:     80] loss: 0.01602 time model: 0.27596 acc: 0.82812\n",
      "100\n",
      "[epoch: 10, batch:    100] loss: 0.01581 time model: 0.27596 acc: 0.82906\n",
      "epoch:10 train loss: 0.015855731403509182 train acc: 0.8264866417696064 valid loss: 0.02031844307978948 valid acc: 0.8133333333333334\n",
      "epoch:10 train loss: 0.015855731403509182 train acc: 0.8264866417696064 valid loss: 0.02031844307978948 valid acc: 0.8133333333333334\n",
      "Lowest validation loss: 0.02031844307978948, Epoch num: 9\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=fgsm, \n",
    "                      epsilon=0.3, \n",
    "                      alpha=None, \n",
    "                      num_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_10_epochs_pgd_0.05_0.02_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[epoch: 1, batch:     20] loss: 0.12136 time model: 0.23699 acc: 0.05312\n",
      "40\n",
      "[epoch: 1, batch:     40] loss: 0.11239 time model: 0.23313 acc: 0.07891\n",
      "60\n",
      "[epoch: 1, batch:     60] loss: 0.10858 time model: 0.23223 acc: 0.08906\n",
      "80\n",
      "[epoch: 1, batch:     80] loss: 0.10608 time model: 0.23187 acc: 0.09414\n",
      "100\n",
      "[epoch: 1, batch:    100] loss: 0.10369 time model: 0.23161 acc: 0.10375\n",
      "epoch:1 train loss: 0.10287262447535803 train acc: 0.10830221200804367 valid loss: 0.09774765014648437 valid acc: 0.18\n",
      "epoch:1 train loss: 0.10287262447535803 train acc: 0.10830221200804367 valid loss: 0.09774765014648437 valid acc: 0.18\n",
      "20\n",
      "[epoch: 2, batch:     20] loss: 0.08369 time model: 0.23015 acc: 0.18906\n",
      "40\n",
      "[epoch: 2, batch:     40] loss: 0.07998 time model: 0.23028 acc: 0.23047\n",
      "60\n",
      "[epoch: 2, batch:     60] loss: 0.07713 time model: 0.23009 acc: 0.25052\n",
      "80\n",
      "[epoch: 2, batch:     80] loss: 0.07448 time model: 0.23007 acc: 0.27813\n",
      "100\n",
      "[epoch: 2, batch:    100] loss: 0.07293 time model: 0.23009 acc: 0.28969\n",
      "epoch:2 train loss: 0.07186546283903837 train acc: 0.30020109164033326 valid loss: 0.061101178328196205 valid acc: 0.41333333333333333\n",
      "epoch:2 train loss: 0.07186546283903837 train acc: 0.30020109164033326 valid loss: 0.061101178328196205 valid acc: 0.41333333333333333\n",
      "20\n",
      "[epoch: 3, batch:     20] loss: 0.05843 time model: 0.23015 acc: 0.42344\n",
      "40\n",
      "[epoch: 3, batch:     40] loss: 0.05733 time model: 0.23007 acc: 0.42969\n",
      "60\n",
      "[epoch: 3, batch:     60] loss: 0.05653 time model: 0.23015 acc: 0.42552\n",
      "80\n",
      "[epoch: 3, batch:     80] loss: 0.05525 time model: 0.23022 acc: 0.44180\n",
      "100\n",
      "[epoch: 3, batch:    100] loss: 0.05426 time model: 0.23025 acc: 0.44688\n",
      "epoch:3 train loss: 0.053455647022276905 train acc: 0.45504165469692615 valid loss: 0.050373094081878664 valid acc: 0.5066666666666667\n",
      "epoch:3 train loss: 0.053455647022276905 train acc: 0.45504165469692615 valid loss: 0.050373094081878664 valid acc: 0.5066666666666667\n",
      "20\n",
      "[epoch: 4, batch:     20] loss: 0.04910 time model: 0.23038 acc: 0.52031\n",
      "40\n",
      "[epoch: 4, batch:     40] loss: 0.04891 time model: 0.23065 acc: 0.51094\n",
      "60\n",
      "[epoch: 4, batch:     60] loss: 0.04677 time model: 0.23075 acc: 0.52396\n",
      "80\n",
      "[epoch: 4, batch:     80] loss: 0.04533 time model: 0.23078 acc: 0.53945\n",
      "100\n",
      "[epoch: 4, batch:    100] loss: 0.04410 time model: 0.23087 acc: 0.55219\n",
      "epoch:4 train loss: 0.04331200378306191 train acc: 0.5601838552140189 valid loss: 0.03724605997403463 valid acc: 0.6066666666666667\n",
      "epoch:4 train loss: 0.04331200378306191 train acc: 0.5601838552140189 valid loss: 0.03724605997403463 valid acc: 0.6066666666666667\n",
      "20\n",
      "[epoch: 5, batch:     20] loss: 0.03750 time model: 0.23189 acc: 0.60625\n",
      "40\n",
      "[epoch: 5, batch:     40] loss: 0.03670 time model: 0.23195 acc: 0.61328\n",
      "60\n",
      "[epoch: 5, batch:     60] loss: 0.03680 time model: 0.23197 acc: 0.61927\n",
      "80\n",
      "[epoch: 5, batch:     80] loss: 0.03589 time model: 0.23197 acc: 0.62383\n",
      "100\n",
      "[epoch: 5, batch:    100] loss: 0.03546 time model: 0.23200 acc: 0.62500\n",
      "epoch:5 train loss: 0.03550153558057672 train acc: 0.6239586325768457 valid loss: 0.03288592418034871 valid acc: 0.64\n",
      "epoch:5 train loss: 0.03550153558057672 train acc: 0.6239586325768457 valid loss: 0.03288592418034871 valid acc: 0.64\n",
      "20\n",
      "[epoch: 6, batch:     20] loss: 0.02890 time model: 0.23150 acc: 0.67031\n",
      "40\n",
      "[epoch: 6, batch:     40] loss: 0.03012 time model: 0.23116 acc: 0.66719\n",
      "60\n",
      "[epoch: 6, batch:     60] loss: 0.03023 time model: 0.23093 acc: 0.66875\n",
      "80\n",
      "[epoch: 6, batch:     80] loss: 0.02998 time model: 0.23085 acc: 0.67539\n",
      "100\n",
      "[epoch: 6, batch:    100] loss: 0.02943 time model: 0.23076 acc: 0.68281\n",
      "epoch:6 train loss: 0.029432196104810758 train acc: 0.6825624820453893 valid loss: 0.024547207554181417 valid acc: 0.7733333333333333\n",
      "epoch:6 train loss: 0.029432196104810758 train acc: 0.6825624820453893 valid loss: 0.024547207554181417 valid acc: 0.7733333333333333\n",
      "20\n",
      "[epoch: 7, batch:     20] loss: 0.02732 time model: 0.23055 acc: 0.70625\n",
      "40\n",
      "[epoch: 7, batch:     40] loss: 0.02694 time model: 0.23059 acc: 0.71406\n",
      "60\n",
      "[epoch: 7, batch:     60] loss: 0.02629 time model: 0.23055 acc: 0.71406\n",
      "80\n",
      "[epoch: 7, batch:     80] loss: 0.02572 time model: 0.23068 acc: 0.71758\n",
      "100\n",
      "[epoch: 7, batch:    100] loss: 0.02555 time model: 0.23081 acc: 0.71688\n",
      "20\n",
      "[epoch: 8, batch:     20] loss: 0.02189 time model: 0.23080 acc: 0.75781\n",
      "40\n",
      "[epoch: 8, batch:     40] loss: 0.02195 time model: 0.23052 acc: 0.75000\n",
      "60\n",
      "[epoch: 8, batch:     60] loss: 0.02229 time model: 0.23036 acc: 0.75417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3ca406f741c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                       num_iter=10)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-9c4789412034>\u001b[0m in \u001b[0;36mfit_model_new\u001b[0;34m(self, optimizer, n_epochs, LOGFILE_PATH, model_filename, attack, epsilon, alpha, num_iter)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m           \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGFILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-9c4789412034>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, epoch, loader, LOGFILE_PATH, optimizer, attack, epsilon, alpha, num_iter)\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Speaker Verification/models/resnet.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Speaker Verification/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=pgd_linf, \n",
    "                      epsilon=0.05, \n",
    "                      alpha=0.02, \n",
    "                      num_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_10_epochs_pgd_0.1_0.05_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit_model_new(optimizer=torch.optim.Adam(model.parameters(), lr=.001), \n",
    "                      n_epochs=10, \n",
    "                      LOGFILE_PATH=LOGFILE_PATH,\n",
    "                      model_filename=MODELNAME, \n",
    "                      attack=pgd_linf, \n",
    "                      epsilon=0.1, \n",
    "                      alpha=0.05, \n",
    "                      num_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = '10_uids_10_epochs_pgd_0.3_0.1_sp'\n",
    "LOGFILE_PATH = 'logs/' + MODELNAME\n",
    "\n",
    "model = resnet34(pretrained=False, progress=False).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    '10_uids_normal_10_epochs_sp',\n",
    "    '10_uids_fgsm_.05_10_epochs_sp',\n",
    "    '10_uids_10_epochs_fgsm_0.1_sp',\n",
    "    '10_uids_10_epochs_fgsm_0.3_sp',\n",
    "    '10_uids_10_epochs_pgd_0.05_0.02_sp',\n",
    "    '10_uids_10_epochs_pgd_0.1_0.05_sp',\n",
    "    '10_uids_10_epochs_pgd_0.3_0.1_sp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_params = {\n",
    "    'none': (None, None, None, None),\n",
    "    'fgsm_.05': (fgsm, 0.05, None, None),\n",
    "    'fgsm_.1': (fgsm, 0.1, None, None),\n",
    "    'fgsm_.3': (fgsm, 0.3, None, None),\n",
    "    'pgd_.05_.02': (pgd_linf, 0.05, 0.02, 20),\n",
    "    'pgd_.1_.05': (pgd_linf, 0.1, 0.05, 20),\n",
    "    'pgd_.3_.1': (pgd_linf, 0.3, 0.1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_uids_normal_10_epochs_lr_0.001\n",
      "30_uids_fgsm_05_10_epochs_lr_0.001\n",
      "30_uids_10_epochs_lr_0.001_fgsm_01\n",
      "30_uids_epochs_lr_0.001_pgd_05_05\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = load_model('saved/' + str(model_name))\n",
    "    model = model.eval()\n",
    "    LOGFILE_PATH = MODELNAME + '_eval'\n",
    "    trainer = BaseTrainer(model=model, \n",
    "                      train_dl=train_data_loader, \n",
    "                      valid_dl=valid_data_loader, \n",
    "                      criterion=criterion, \n",
    "                      model_filename=MODELNAME, \n",
    "                      n_epochs=3)\n",
    "    model_results = {}\n",
    "    for param_key in attack_params.keys():\n",
    "        params = attack_params[param_key]\n",
    "        attack = params[0]\n",
    "        epsilon = params[1]\n",
    "        alpha = params[2]\n",
    "        num_iter = params[3]\n",
    "        \n",
    "        loss, acc = trainer.run_epoch(0, valid_data_loader, LOGFILE_PATH, optimizer=None, attack=attack, \n",
    "                          epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "        \n",
    "        if attack!=fgsm:\n",
    "            model_results['pgd' + '_eps_' + str(epsilon) + '_alpha_' + str(alpha) + '_num_iter_' + str(num_iter)] = acc\n",
    "        else:\n",
    "            model_results['fgsm' + '_eps_' + str(epsilon)] = acc\n",
    "\n",
    "            \n",
    "    results[model_name] = model_results\n",
    "    \n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('results_speaker_verification_spectrograms.csv')\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
